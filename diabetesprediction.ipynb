{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetesprediction.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/YazCodes/diabetes-prediction-DL/blob/main/diabetesprediction.ipynb",
      "authorship_tag": "ABX9TyP4KK9GqNiwUmplEpzSTFoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YazCodes/diabetes-prediction-DL/blob/main/diabetesprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi6SFTPTjTBV"
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder #need to convert labels - strings into boolean values etc \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "88TE1P0RkWYD",
        "outputId": "f8a0a9a5-2330-4c9a-97cb-7f350e94a6b5"
      },
      "source": [
        "\r\n",
        "#Load training data \r\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/hospitaltrain (1).csv\")\r\n",
        "\r\n",
        "#Load test data\r\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/hospitaltest (1).csv\")\r\n",
        "\r\n",
        "print(f'Number of entries: {len(df_train)}')\r\n",
        "df_train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  A1   A2  A3  A4   A5    A6     A7  A8  Class\n",
              "0   1   6  148  72  35    0  33.6  0.627  50      1\n",
              "1   2   1   85  66  29    0  26.6  0.351  31      0\n",
              "2   3   8  183  64   0    0  23.3  0.672  32      1\n",
              "3   4   1   89  66  23   94  28.1  0.167  21      0\n",
              "4   5   0  137  40  35  168  43.1  2.288  33      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8tEDhLCo34S",
        "outputId": "93c24e42-a1f0-4b05-a35a-fb7376d35ac2"
      },
      "source": [
        "#data set inforation\r\n",
        "\r\n",
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 668 entries, 0 to 667\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Id      668 non-null    int64  \n",
            " 1   A1      668 non-null    int64  \n",
            " 2   A2      668 non-null    int64  \n",
            " 3   A3      668 non-null    int64  \n",
            " 4   A4      668 non-null    int64  \n",
            " 5   A5      668 non-null    int64  \n",
            " 6   A6      668 non-null    float64\n",
            " 7   A7      668 non-null    float64\n",
            " 8   A8      668 non-null    int64  \n",
            " 9   Class   668 non-null    int64  \n",
            "dtypes: float64(2), int64(8)\n",
            "memory usage: 52.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "rPJZhJxDpJtv",
        "outputId": "84eec461-df86-4126-cc8c-ecfa51e1a922"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>334.500000</td>\n",
              "      <td>3.812874</td>\n",
              "      <td>120.405689</td>\n",
              "      <td>68.748503</td>\n",
              "      <td>20.567365</td>\n",
              "      <td>79.654192</td>\n",
              "      <td>31.860180</td>\n",
              "      <td>0.477329</td>\n",
              "      <td>33.091317</td>\n",
              "      <td>0.345808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>192.979273</td>\n",
              "      <td>3.365672</td>\n",
              "      <td>32.291473</td>\n",
              "      <td>19.526392</td>\n",
              "      <td>16.020600</td>\n",
              "      <td>115.827750</td>\n",
              "      <td>7.827111</td>\n",
              "      <td>0.341398</td>\n",
              "      <td>11.711386</td>\n",
              "      <td>0.475988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>167.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>0.238750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>334.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>501.250000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>668.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Id          A1          A2  ...          A7          A8       Class\n",
              "count  668.000000  668.000000  668.000000  ...  668.000000  668.000000  668.000000\n",
              "mean   334.500000    3.812874  120.405689  ...    0.477329   33.091317    0.345808\n",
              "std    192.979273    3.365672   32.291473  ...    0.341398   11.711386    0.475988\n",
              "min      1.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
              "25%    167.750000    1.000000   99.000000  ...    0.238750   24.000000    0.000000\n",
              "50%    334.500000    3.000000  116.000000  ...    0.377000   29.000000    0.000000\n",
              "75%    501.250000    6.000000  140.000000  ...    0.641250   40.000000    1.000000\n",
              "max    668.000000   17.000000  199.000000  ...    2.420000   81.000000    1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "UA3s_7kppTf9",
        "outputId": "f5c05006-0c35-4319-cc1e-507a7b7e24f5"
      },
      "source": [
        "# Summarise class details\r\n",
        "sns.countplot(x=df_train['Class'])\r\n",
        "#Class - 0 or 1 (1= tested positive for diabetes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fead41d0f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANkklEQVR4nO3df6zddX3H8eeLlh8zGz+kd4htsWzWLcQJYsOYZouDmAHbLCNgcNN2rkm3hC2iixOXZU4zE81+IP6YSyc/CllAJlOYI3OEH2NLFG0V+RljJTLaFFqhoGhwFt/743764ba09AD9nnPb+3wkN/1+P9/vPbxv0vDs99xzvidVhSRJAAdNegBJ0uxhFCRJnVGQJHVGQZLUGQVJUjd/0gO8GAsWLKglS5ZMegxJ2q+sX7/+u1U1tbtj+3UUlixZwrp16yY9hiTtV5I8uKdjPn0kSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnq9ut3NO8Lr3vPlZMeQbPQ+r9ZMekRpInwSkGS1BkFSVJnFCRJnVGQJHVGQZLUGQVJUmcUJEmdUZAkdUZBktQZBUlSZxQkSZ1RkCR1RkGS1A0ehSTzknw9yRfa/vFJ7kiyIclnkhzS1g9t+xva8SVDzyZJ2tk4rhTeCdw/Y/8jwMVV9UpgG7Cqra8CtrX1i9t5kqQxGjQKSRYBvwl8uu0HOA34bDtlLXB2217e9mnHT2/nS5LGZOgrhY8Cfwb8pO0fDTxeVdvb/kZgYdteCDwE0I4/0c7fSZLVSdYlWbd169YhZ5ekOWewKCT5LWBLVa3fl49bVWuqallVLZuamtqXDy1Jc96QH8f5BuDNSc4CDgMOBy4Bjkwyv10NLAI2tfM3AYuBjUnmA0cAjw44nyRpF4NdKVTV+6pqUVUtAc4Hbqmq3wNuBc5tp60Erm/bN7R92vFbqqqGmk+S9GyTeJ/Ce4F3J9nA9O8MLm3rlwJHt/V3AxdNYDZJmtOGfPqoq6rbgNva9gPAKbs55yngvHHMI0naPd/RLEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqRssCkkOS/KVJN9Icm+SD7T145PckWRDks8kOaStH9r2N7TjS4aaTZK0e0NeKfwIOK2qTgROAs5IcirwEeDiqnolsA1Y1c5fBWxr6xe38yRJYzRYFGrak2334PZVwGnAZ9v6WuDstr287dOOn54kQ80nSXq2QX+nkGRekjuBLcBNwLeBx6tqeztlI7CwbS8EHgJox58Ajh5yPknSzgaNQlU9XVUnAYuAU4BffLGPmWR1knVJ1m3duvVFzyhJesZYXn1UVY8DtwK/AhyZZH47tAjY1LY3AYsB2vEjgEd381hrqmpZVS2bmpoafHZJmkuGfPXRVJIj2/ZPAW8C7mc6Due201YC17ftG9o+7fgtVVVDzSdJerb5ez/lBTsWWJtkHtPxubaqvpDkPuCaJH8NfB24tJ1/KXBVkg3AY8D5A84mSdqNwaJQVXcBr93N+gNM/35h1/WngPOGmkeStHe+o1mS1BkFSVJnFCRJnVGQJHVGQZLUGQVJUmcUJEmdUZAkdUZBktQZBUlSZxQkSZ1RkCR1RkGS1BkFSVJnFCRJnVGQJHVGQZLUjRSFJDePsiZJ2r8958dxJjkMeAmwIMlRQNqhw4GFA88mSRqzvX1G8x8CFwIvB9bzTBS+B3xiwLkkSRPwnFGoqkuAS5L8SVV9fEwzSZImZG9XCgBU1ceTvB5YMvN7qurKgeaSJE3ASFFIchXw88CdwNNtuQCjIEkHkJGiACwDTqiqGnIYSdJkjfo+hXuAlw05iCRp8ka9UlgA3JfkK8CPdixW1ZsHmUqSNBGjRuGvhhxCkjQ7jPrqo/8aehBJO/vfD/7SpEfQLHTcX9496OOP+uqj7zP9aiOAQ4CDgR9U1eFDDSZJGr9RrxR+Zsd2kgDLgVOHGkqSNBnP+y6pNe3zwG8MMI8kaYJGffronBm7BzH9voWnBplIkjQxo7766LdnbG8HvsP0U0iSpAPIqL9TeMfQg0iSJm/UD9lZlORzSba0r+uSLBp6OEnSeI36i+bLgRuY/lyFlwP/1tYkSQeQUaMwVVWXV9X29nUFMDXgXJKkCRg1Co8meVuSee3rbcCjQw4mSRq/UaPwB8BbgIeBzcC5wO8PNJMkaUJGjcIHgZVVNVVVP8t0JD7wXN+QZHGSW5Pcl+TeJO9s6y9NclOSb7U/j2rrSfKxJBuS3JXk5Bfzg0mSnr9Ro/Caqtq2Y6eqHgNeu5fv2Q78aVWdwPQtMS5IcgJwEXBzVS0Fbm77AGcCS9vXauBTI/8UkqR9YtQoHLTjX/Qw/a999vIeh6raXFVfa9vfB+4HFjL9pre17bS1wNltezlwZbuNxpeBI5McO/JPIkl60UZ9R/PfAV9K8i9t/zzgQ6P+R5IsYfrK4g7gmKra3A49DBzTthcCD834to1tbfOMNZKsZvpKguOOO27UESRJIxjpSqGqrgTOAR5pX+dU1VWjfG+SnwauAy6squ/t8rjFM7fkHklVramqZVW1bGrKV8VK0r406pUCVXUfcN/zefAkBzMdhH+uqn9ty48kObaqNrenh7a09U3A4hnfvqitSZLG5HnfOntU7XMXLgXur6q/n3HoBmBl214JXD9jfUV7FdKpwBMznmaSJI3ByFcKL8AbgLcDdye5s639OfBh4Nokq4AHmX7/A8CNwFnABuCHgDfhk6QxGywKVfU/QPZw+PTdnF/ABUPNI0nau8GePpIk7X+MgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpMwqSpM4oSJI6oyBJ6oyCJKkzCpKkzihIkjqjIEnqjIIkqTMKkqTOKEiSOqMgSeqMgiSpGywKSS5LsiXJPTPWXprkpiTfan8e1daT5GNJNiS5K8nJQ80lSdqzIa8UrgDO2GXtIuDmqloK3Nz2Ac4Elrav1cCnBpxLkrQHg0Whqm4HHttleTmwtm2vBc6esX5lTfsycGSSY4eaTZK0e+P+ncIxVbW5bT8MHNO2FwIPzThvY1t7liSrk6xLsm7r1q3DTSpJc9DEftFcVQXUC/i+NVW1rKqWTU1NDTCZJM1d447CIzueFmp/bmnrm4DFM85b1NYkSWM07ijcAKxs2yuB62esr2ivQjoVeGLG00ySpDGZP9QDJ7kaeCOwIMlG4P3Ah4Frk6wCHgTe0k6/ETgL2AD8EHjHUHNJkvZssChU1Vv3cOj03ZxbwAVDzSJJGo3vaJYkdUZBktQZBUlSZxQkSZ1RkCR1RkGS1BkFSVJnFCRJnVGQJHVGQZLUGQVJUmcUJEmdUZAkdUZBktQZBUlSZxQkSZ1RkCR1RkGS1BkFSVJnFCRJnVGQJHVGQZLUGQVJUmcUJEmdUZAkdUZBktQZBUlSZxQkSZ1RkCR1RkGS1BkFSVJnFCRJnVGQJHVGQZLUGQVJUmcUJEmdUZAkdUZBktQZBUlSN6uikOSMJN9MsiHJRZOeR5LmmlkThSTzgE8CZwInAG9NcsJkp5KkuWXWRAE4BdhQVQ9U1f8B1wDLJzyTJM0p8yc9wAwLgYdm7G8EfnnXk5KsBla33SeTfHMMs80VC4DvTnqI2SB/u3LSI2hn/t3c4f3ZF4/yij0dmE1RGElVrQHWTHqOA1GSdVW1bNJzSLvy7+b4zKanjzYBi2fsL2prkqQxmU1R+CqwNMnxSQ4BzgdumPBMkjSnzJqnj6pqe5I/Br4IzAMuq6p7JzzWXOPTcpqt/Ls5JqmqSc8gSZolZtPTR5KkCTMKkqTOKMjbi2jWSnJZki1J7pn0LHOFUZjjvL2IZrkrgDMmPcRcYhTk7UU0a1XV7cBjk55jLjEK2t3tRRZOaBZJE2YUJEmdUZC3F5HUGQV5exFJnVGY46pqO7Dj9iL3A9d6exHNFkmuBr4E/EKSjUlWTXqmA523uZAkdV4pSJI6oyBJ6oyCJKkzCpKkzihIkjqjII0oycuSXJPk20nWJ7kxyau8g6cOJLPm4zil2SxJgM8Ba6vq/LZ2InDMRAeT9jGvFKTR/Drw46r6xx0LVfUNZtxMMMmSJP+d5Gvt6/Vt/dgktye5M8k9SX41ybwkV7T9u5O8a/w/kvRsXilIo3k1sH4v52wB3lRVTyVZClwNLAN+F/hiVX2ofX7FS4CTgIVV9WqAJEcON7o0OqMg7TsHA59IchLwNPCqtv5V4LIkBwOfr6o7kzwA/FySjwP/DvznRCaWduHTR9Jo7gVet5dz3gU8ApzI9BXCIdA/KObXmL777BVJVlTVtnbebcAfAZ8eZmzp+TEK0mhuAQ5NsnrHQpLXsPNtx48ANlfVT4C3A/Paea8AHqmqf2L6f/4nJ1kAHFRV1wF/AZw8nh9Dem4+fSSNoKoqye8AH03yXuAp4DvAhTNO+wfguiQrgP8AftDW3wi8J8mPgSeBFUx/ut3lSXb8w+x9g/8Q0gi8S6okqfPpI0lSZxQkSZ1RkCR1RkGS1BkFSVJnFCRJnVGQJHX/DzlfCTtgzHe3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "RmeV8gbdqaEx",
        "outputId": "57a6d6c3-476a-4459-8112-da122fa67fdd"
      },
      "source": [
        "#Data pre-processing \r\n",
        "df_train.isnull().values.any() #No missing values \r\n",
        "#The data has a lot of 0 values. But it is not appropriate to use data cleaning to replace the 0 values in the A5 column. \r\n",
        "#As the A5 column represents the amount of insulin a patient has it would be wrong of us to replace the 0 values with a mean value. \r\n",
        "#We don't want to alter patient records.\r\n",
        "\r\n",
        "#removing unnecessary columns\r\n",
        "#x is training data it contains features and models - 'Class' is something we need to PREDICT therefore we need to drop that column \r\n",
        "X = df_train.drop(['Id', 'Class'], axis=1) #Class is not a feature it's just a label  axis = 1 shows we are using columns \r\n",
        "print(X.info())\r\n",
        "X.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 668 entries, 0 to 667\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      668 non-null    int64  \n",
            " 1   A2      668 non-null    int64  \n",
            " 2   A3      668 non-null    int64  \n",
            " 3   A4      668 non-null    int64  \n",
            " 4   A5      668 non-null    int64  \n",
            " 5   A6      668 non-null    float64\n",
            " 6   A7      668 non-null    float64\n",
            " 7   A8      668 non-null    int64  \n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 41.9 KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A1   A2  A3  A4   A5    A6     A7  A8\n",
              "0   6  148  72  35    0  33.6  0.627  50\n",
              "1   1   85  66  29    0  26.6  0.351  31\n",
              "2   8  183  64   0    0  23.3  0.672  32\n",
              "3   1   89  66  23   94  28.1  0.167  21\n",
              "4   0  137  40  35  168  43.1  2.288  33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIL48450w2No",
        "outputId": "b51525db-5073-4204-a232-a2b3bdbfca02"
      },
      "source": [
        "#Extracting labels and features \r\n",
        "\r\n",
        "#Extracting labels \r\n",
        "y= df_train['Class']\r\n",
        "print(y.value_counts())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    437\n",
            "1    231\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351n593syTkQ"
      },
      "source": [
        "#Since the labels 0 and 1 are already are numerical values they do not need to be converted for the model.\r\n",
        "#If the labels were in a catergorical state then you could use the label encoder to convert them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "9NK1cVpqy-zh",
        "outputId": "31637cce-9fe3-472d-8093-73966195c235"
      },
      "source": [
        "#MODEL ONE\r\n",
        "\r\n",
        "#Using 8 features and 2 hidden layers \r\n",
        "#building the model - using training data \r\n",
        "#calculating if the probability is closer to 0 or 1 \r\n",
        "X1 = X.iloc[:, 0:8] #locating part of the data frame the first 8 and call it X1 \r\n",
        "X1.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A1   A2  A3  A4   A5    A6     A7  A8\n",
              "0   6  148  72  35    0  33.6  0.627  50\n",
              "1   1   85  66  29    0  26.6  0.351  31\n",
              "2   8  183  64   0    0  23.3  0.672  32\n",
              "3   1   89  66  23   94  28.1  0.167  21\n",
              "4   0  137  40  35  168  43.1  2.288  33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgw1Q-xjzWxy",
        "outputId": "ca15d017-af35-40d8-dccc-ae15ea5084b2"
      },
      "source": [
        "#Spliting the data into train (70%) and validation (30%)\r\n",
        "X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y, test_size=0.3, random_state=100) #random state - regenerate the split again \r\n",
        "print(f'training data set size: {len(X_train1)}')\r\n",
        "print(f'validation data set size: {len(X_val1)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data set size: 467\n",
            "validation data set size: 201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNzyZXHZz5oE",
        "outputId": "a1c4c102-60b1-4595-a755-d33127c109fa"
      },
      "source": [
        "#Building model One\r\n",
        "\r\n",
        "# define the keras model\r\n",
        "model1 = Sequential()\r\n",
        "model1.add(Dense(12, input_dim=8, activation='relu')) #Defining our hidden layer - adding the layers to the model, a dence layer, 12 neurons, we selected 8 features so 8 input dimentions .\r\n",
        "model1.add(Dense(8, activation='relu')) #second hidden layer\r\n",
        "#using relu for hidden layers not for output layers \r\n",
        "model1.add(Dense(1, activation='sigmoid')) #creating our output layer with one neurone \r\n",
        "\r\n",
        "model1.summary()\r\n",
        "\r\n",
        "#parameters = the total of weights and bias "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kK_3_1R2ATw"
      },
      "source": [
        "# compile the keras model\r\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCNWYhra2Knu",
        "outputId": "ab04d4f3-644f-4b19-ddbb-6ea1014954cd"
      },
      "source": [
        "# train model one - part 1\r\n",
        "#model1.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1)) #change depending on your dataset  batch_size and epochs- you have to look at the accuracy of the dataset \r\n",
        "\r\n",
        "#Epoch 60/60\r\n",
        "#10/10 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6782 - val_loss: 0.6478 - val_accuracy: 0.6716"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "10/10 [==============================] - 1s 31ms/step - loss: 3.7418 - accuracy: 0.3991 - val_loss: 2.4649 - val_accuracy: 0.4428\n",
            "Epoch 2/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4980 - accuracy: 0.4369 - val_loss: 2.0681 - val_accuracy: 0.4279\n",
            "Epoch 3/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5355 - accuracy: 0.4316 - val_loss: 1.7451 - val_accuracy: 0.4478\n",
            "Epoch 4/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9790 - accuracy: 0.4600 - val_loss: 1.4849 - val_accuracy: 0.4428\n",
            "Epoch 5/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0643 - accuracy: 0.4625 - val_loss: 1.3298 - val_accuracy: 0.4478\n",
            "Epoch 6/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5816 - accuracy: 0.4646 - val_loss: 1.2303 - val_accuracy: 0.4577\n",
            "Epoch 7/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3786 - accuracy: 0.4792 - val_loss: 1.1309 - val_accuracy: 0.4726\n",
            "Epoch 8/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2712 - accuracy: 0.5071 - val_loss: 1.0922 - val_accuracy: 0.4627\n",
            "Epoch 9/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1167 - accuracy: 0.5538 - val_loss: 1.0410 - val_accuracy: 0.4776\n",
            "Epoch 10/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9809 - accuracy: 0.5627 - val_loss: 1.0755 - val_accuracy: 0.4776\n",
            "Epoch 11/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9061 - accuracy: 0.5681 - val_loss: 0.9736 - val_accuracy: 0.4876\n",
            "Epoch 12/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.5633 - val_loss: 1.0241 - val_accuracy: 0.4776\n",
            "Epoch 13/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8837 - accuracy: 0.5867 - val_loss: 0.9625 - val_accuracy: 0.5124\n",
            "Epoch 14/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8536 - accuracy: 0.5948 - val_loss: 0.9334 - val_accuracy: 0.5224\n",
            "Epoch 15/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8415 - accuracy: 0.6238 - val_loss: 0.9075 - val_accuracy: 0.5423\n",
            "Epoch 16/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8322 - accuracy: 0.6030 - val_loss: 0.9195 - val_accuracy: 0.5124\n",
            "Epoch 17/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8098 - accuracy: 0.6036 - val_loss: 0.8738 - val_accuracy: 0.5622\n",
            "Epoch 18/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7719 - accuracy: 0.6172 - val_loss: 0.9072 - val_accuracy: 0.5274\n",
            "Epoch 19/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8093 - accuracy: 0.6016 - val_loss: 0.8539 - val_accuracy: 0.5672\n",
            "Epoch 20/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7939 - accuracy: 0.6326 - val_loss: 0.8631 - val_accuracy: 0.5572\n",
            "Epoch 21/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7544 - accuracy: 0.6225 - val_loss: 0.8344 - val_accuracy: 0.5672\n",
            "Epoch 22/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7227 - accuracy: 0.6447 - val_loss: 0.8374 - val_accuracy: 0.5721\n",
            "Epoch 23/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6620 - accuracy: 0.6783 - val_loss: 0.8155 - val_accuracy: 0.5821\n",
            "Epoch 24/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7533 - accuracy: 0.6303 - val_loss: 0.8184 - val_accuracy: 0.5721\n",
            "Epoch 25/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7058 - accuracy: 0.6505 - val_loss: 0.8112 - val_accuracy: 0.5771\n",
            "Epoch 26/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.6637 - val_loss: 0.7908 - val_accuracy: 0.5970\n",
            "Epoch 27/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7065 - accuracy: 0.6635 - val_loss: 0.7961 - val_accuracy: 0.5970\n",
            "Epoch 28/60\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7029 - accuracy: 0.6521 - val_loss: 0.7871 - val_accuracy: 0.5920\n",
            "Epoch 29/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6706 - accuracy: 0.6636 - val_loss: 0.7743 - val_accuracy: 0.6169\n",
            "Epoch 30/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.6630 - val_loss: 0.7613 - val_accuracy: 0.6169\n",
            "Epoch 31/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6580 - accuracy: 0.6734 - val_loss: 0.7847 - val_accuracy: 0.5821\n",
            "Epoch 32/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6755 - val_loss: 0.7593 - val_accuracy: 0.6070\n",
            "Epoch 33/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6647 - accuracy: 0.6621 - val_loss: 0.7532 - val_accuracy: 0.6119\n",
            "Epoch 34/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.6660 - val_loss: 0.7419 - val_accuracy: 0.6219\n",
            "Epoch 35/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.6499 - val_loss: 0.7541 - val_accuracy: 0.6020\n",
            "Epoch 36/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6317 - accuracy: 0.7025 - val_loss: 0.7305 - val_accuracy: 0.6418\n",
            "Epoch 37/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6407 - accuracy: 0.6802 - val_loss: 0.7326 - val_accuracy: 0.6318\n",
            "Epoch 38/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6984 - val_loss: 0.7203 - val_accuracy: 0.6219\n",
            "Epoch 39/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.6591 - val_loss: 0.7303 - val_accuracy: 0.6169\n",
            "Epoch 40/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6622 - val_loss: 0.7130 - val_accuracy: 0.6517\n",
            "Epoch 41/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.7019 - val_loss: 0.7179 - val_accuracy: 0.6318\n",
            "Epoch 42/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6628 - accuracy: 0.6507 - val_loss: 0.7070 - val_accuracy: 0.6468\n",
            "Epoch 43/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.6840 - val_loss: 0.7047 - val_accuracy: 0.6318\n",
            "Epoch 44/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.7027 - val_loss: 0.7009 - val_accuracy: 0.6269\n",
            "Epoch 45/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6238 - accuracy: 0.6981 - val_loss: 0.6975 - val_accuracy: 0.6418\n",
            "Epoch 46/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6006 - accuracy: 0.7040 - val_loss: 0.6940 - val_accuracy: 0.6418\n",
            "Epoch 47/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6359 - accuracy: 0.6867 - val_loss: 0.6905 - val_accuracy: 0.6468\n",
            "Epoch 48/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.6785 - val_loss: 0.6824 - val_accuracy: 0.6517\n",
            "Epoch 49/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7042 - val_loss: 0.6804 - val_accuracy: 0.6418\n",
            "Epoch 50/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7105 - val_loss: 0.6687 - val_accuracy: 0.6567\n",
            "Epoch 51/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6833 - val_loss: 0.6775 - val_accuracy: 0.6368\n",
            "Epoch 52/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6756 - val_loss: 0.6718 - val_accuracy: 0.6517\n",
            "Epoch 53/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7200 - val_loss: 0.6638 - val_accuracy: 0.6517\n",
            "Epoch 54/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5746 - accuracy: 0.7280 - val_loss: 0.6617 - val_accuracy: 0.6517\n",
            "Epoch 55/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.6846 - val_loss: 0.6737 - val_accuracy: 0.6318\n",
            "Epoch 56/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.6850 - val_loss: 0.6603 - val_accuracy: 0.6517\n",
            "Epoch 57/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.6834 - val_loss: 0.6679 - val_accuracy: 0.6517\n",
            "Epoch 58/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.6744 - val_loss: 0.6593 - val_accuracy: 0.6468\n",
            "Epoch 59/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.6903 - val_loss: 0.6664 - val_accuracy: 0.6318\n",
            "Epoch 60/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6782 - val_loss: 0.6478 - val_accuracy: 0.6716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea97153978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dTfiIz32ifC",
        "outputId": "f854ccd1-f11d-446f-fa78-5ba270c9902a"
      },
      "source": [
        "#Train model one part 2 \r\n",
        "#model1.fit(X_train1, y_train1, batch_size=40, epochs=50, validation_data=(X_val1, y_val1)) #change depending on your dataset  batch_size and epochs- you have to look at the accuracy of the dataset "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5927 - accuracy: 0.6809 - val_loss: 0.6664 - val_accuracy: 0.6418\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.6959 - val_loss: 0.6439 - val_accuracy: 0.6617\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.6895 - val_loss: 0.6651 - val_accuracy: 0.6368\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7024 - val_loss: 0.6347 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6895 - val_loss: 0.6927 - val_accuracy: 0.6368\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6874 - val_loss: 0.6353 - val_accuracy: 0.6617\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6959 - val_loss: 0.6375 - val_accuracy: 0.6617\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.6916 - val_loss: 0.6286 - val_accuracy: 0.6716\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6981 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.7045 - val_loss: 0.6416 - val_accuracy: 0.6617\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7109 - val_loss: 0.6285 - val_accuracy: 0.6716\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7088 - val_loss: 0.6426 - val_accuracy: 0.6468\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7173 - val_loss: 0.6198 - val_accuracy: 0.6766\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.6938 - val_loss: 0.6418 - val_accuracy: 0.6617\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7173 - val_loss: 0.6175 - val_accuracy: 0.6866\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.7002 - val_loss: 0.6222 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5687 - accuracy: 0.7002 - val_loss: 0.6424 - val_accuracy: 0.6617\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.6895 - val_loss: 0.6141 - val_accuracy: 0.6866\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7002 - val_loss: 0.6254 - val_accuracy: 0.6816\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7002 - val_loss: 0.6226 - val_accuracy: 0.6716\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7152 - val_loss: 0.6194 - val_accuracy: 0.6766\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7024 - val_loss: 0.6260 - val_accuracy: 0.6716\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7152 - val_loss: 0.6267 - val_accuracy: 0.6716\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7088 - val_loss: 0.6349 - val_accuracy: 0.6716\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7131 - val_loss: 0.6096 - val_accuracy: 0.6915\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7045 - val_loss: 0.6070 - val_accuracy: 0.6866\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.6959 - val_loss: 0.6356 - val_accuracy: 0.6766\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7024 - val_loss: 0.6102 - val_accuracy: 0.6866\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7002 - val_loss: 0.6023 - val_accuracy: 0.6965\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7173 - val_loss: 0.6136 - val_accuracy: 0.6766\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7173 - val_loss: 0.6090 - val_accuracy: 0.6766\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7024 - val_loss: 0.6229 - val_accuracy: 0.6766\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.7281 - val_loss: 0.6033 - val_accuracy: 0.6965\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7045 - val_loss: 0.6141 - val_accuracy: 0.6766\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7302 - val_loss: 0.6003 - val_accuracy: 0.6915\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7088 - val_loss: 0.6219 - val_accuracy: 0.6866\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5521 - accuracy: 0.7195 - val_loss: 0.6096 - val_accuracy: 0.6816\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7045 - val_loss: 0.6055 - val_accuracy: 0.6816\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7045 - val_loss: 0.6167 - val_accuracy: 0.6866\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7302 - val_loss: 0.5952 - val_accuracy: 0.7015\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7109 - val_loss: 0.6031 - val_accuracy: 0.6716\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7109 - val_loss: 0.6065 - val_accuracy: 0.6866\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7323 - val_loss: 0.5960 - val_accuracy: 0.6965\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7109 - val_loss: 0.6257 - val_accuracy: 0.6816\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7152 - val_loss: 0.5970 - val_accuracy: 0.7065\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7109 - val_loss: 0.5953 - val_accuracy: 0.6915\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7024 - val_loss: 0.6067 - val_accuracy: 0.6716\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.7195 - val_loss: 0.5919 - val_accuracy: 0.7065\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7281 - val_loss: 0.5919 - val_accuracy: 0.7114\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7066 - val_loss: 0.5973 - val_accuracy: 0.6816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea939b25f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNwyM4Kt3Gbo",
        "outputId": "bd9fad31-d188-4af1-c7f9-ebe662a4d132"
      },
      "source": [
        "# train model one part 3 - The optimum number of batch size and epochs for the parameters of model one\r\n",
        "\r\n",
        "#batch size refers to the number of samples that will be spread within the network.\r\n",
        "#It all depends on your data set size\r\n",
        "#batch size set to 60 = the algorithm takes the first 60 samples from the training dataset to train the network\r\n",
        "#Pros - using a batch size smaller than the sample size is that it uses less memory, the networks will train faster\r\n",
        "#Cons - of using a < batch size will result in a decrease in the accuracy of the gradient. \r\n",
        "\r\n",
        "#Epoch - one forward pass and one background pass of all the training data aka one full cycle through the training set\r\n",
        "model1.fit(X_train1, y_train1, batch_size=60, epochs=70, validation_data=(X_val1, y_val1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5391 - accuracy: 0.7173 - val_loss: 0.5970 - val_accuracy: 0.6965\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7152 - val_loss: 0.5974 - val_accuracy: 0.6915\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7173 - val_loss: 0.5990 - val_accuracy: 0.6766\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7109 - val_loss: 0.5890 - val_accuracy: 0.7015\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7345 - val_loss: 0.6005 - val_accuracy: 0.6716\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7259 - val_loss: 0.5915 - val_accuracy: 0.7015\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7152 - val_loss: 0.5974 - val_accuracy: 0.6766\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7345 - val_loss: 0.5933 - val_accuracy: 0.6915\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5339 - accuracy: 0.7152 - val_loss: 0.5909 - val_accuracy: 0.6965\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5340 - accuracy: 0.7195 - val_loss: 0.5962 - val_accuracy: 0.6766\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7281 - val_loss: 0.5888 - val_accuracy: 0.7015\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7216 - val_loss: 0.5937 - val_accuracy: 0.6866\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7259 - val_loss: 0.5930 - val_accuracy: 0.6866\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.7302 - val_loss: 0.5921 - val_accuracy: 0.6866\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7281 - val_loss: 0.5917 - val_accuracy: 0.6915\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.7238 - val_loss: 0.5852 - val_accuracy: 0.7114\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7409 - val_loss: 0.6003 - val_accuracy: 0.6816\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7430 - val_loss: 0.5859 - val_accuracy: 0.7065\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.7195 - val_loss: 0.5905 - val_accuracy: 0.6965\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7323 - val_loss: 0.5925 - val_accuracy: 0.6866\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7109 - val_loss: 0.5828 - val_accuracy: 0.7164\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 0.7409 - val_loss: 0.5960 - val_accuracy: 0.6816\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7281 - val_loss: 0.5868 - val_accuracy: 0.7015\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5324 - accuracy: 0.7216 - val_loss: 0.5861 - val_accuracy: 0.7114\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.7323 - val_loss: 0.5913 - val_accuracy: 0.6915\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.7281 - val_loss: 0.5832 - val_accuracy: 0.7065\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.7323 - val_loss: 0.5970 - val_accuracy: 0.6915\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7388 - val_loss: 0.5806 - val_accuracy: 0.7264\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7173 - val_loss: 0.5992 - val_accuracy: 0.6965\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7323 - val_loss: 0.5815 - val_accuracy: 0.7164\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7259 - val_loss: 0.5906 - val_accuracy: 0.6866\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.7238 - val_loss: 0.5777 - val_accuracy: 0.7164\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7302 - val_loss: 0.5901 - val_accuracy: 0.6766\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.7323 - val_loss: 0.5778 - val_accuracy: 0.7114\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7238 - val_loss: 0.5780 - val_accuracy: 0.7114\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7516 - val_loss: 0.5865 - val_accuracy: 0.6915\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7281 - val_loss: 0.5766 - val_accuracy: 0.7114\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7173 - val_loss: 0.5846 - val_accuracy: 0.6915\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.7537 - val_loss: 0.5876 - val_accuracy: 0.6816\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7302 - val_loss: 0.5758 - val_accuracy: 0.7164\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7281 - val_loss: 0.5758 - val_accuracy: 0.7015\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7473 - val_loss: 0.5800 - val_accuracy: 0.7015\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.7109 - val_loss: 0.5738 - val_accuracy: 0.7313\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7430 - val_loss: 0.5987 - val_accuracy: 0.6816\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7238 - val_loss: 0.5691 - val_accuracy: 0.7313\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5276 - accuracy: 0.7173 - val_loss: 0.5909 - val_accuracy: 0.6915\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5261 - accuracy: 0.7259 - val_loss: 0.5744 - val_accuracy: 0.7114\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7238 - val_loss: 0.5763 - val_accuracy: 0.7015\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.7366 - val_loss: 0.5753 - val_accuracy: 0.6965\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7366 - val_loss: 0.5726 - val_accuracy: 0.7114\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.7066 - val_loss: 0.5794 - val_accuracy: 0.6965\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.7281 - val_loss: 0.5729 - val_accuracy: 0.7015\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5198 - accuracy: 0.7452 - val_loss: 0.5682 - val_accuracy: 0.7264\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.7323 - val_loss: 0.5833 - val_accuracy: 0.6915\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.7366 - val_loss: 0.5674 - val_accuracy: 0.7363\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5205 - accuracy: 0.7281 - val_loss: 0.5762 - val_accuracy: 0.7015\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7430 - val_loss: 0.5745 - val_accuracy: 0.7164\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.7281 - val_loss: 0.5727 - val_accuracy: 0.7015\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7259 - val_loss: 0.5679 - val_accuracy: 0.7313\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7323 - val_loss: 0.5747 - val_accuracy: 0.7164\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.7388 - val_loss: 0.5631 - val_accuracy: 0.7264\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.7281 - val_loss: 0.5760 - val_accuracy: 0.6965\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.7409 - val_loss: 0.5670 - val_accuracy: 0.7164\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7281 - val_loss: 0.5701 - val_accuracy: 0.7164\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7323 - val_loss: 0.5696 - val_accuracy: 0.7114\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5174 - accuracy: 0.7452 - val_loss: 0.5743 - val_accuracy: 0.7015\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.7388 - val_loss: 0.5636 - val_accuracy: 0.7363\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.7430 - val_loss: 0.5730 - val_accuracy: 0.6965\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7259 - val_loss: 0.5641 - val_accuracy: 0.7313\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.7430 - val_loss: 0.5730 - val_accuracy: 0.7065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea94a662e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf002nDM5UkZ",
        "outputId": "e6c38758-7179-4b6a-d301-98965282861a"
      },
      "source": [
        "# get model predictions for validation data\r\n",
        "y_pred1 = model1.predict(X_val1)\r\n",
        "print(y_pred1[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.39571267]\n",
            " [0.6151204 ]\n",
            " [0.25974202]\n",
            " [0.29754144]\n",
            " [0.6689728 ]\n",
            " [0.07901052]\n",
            " [0.45796472]\n",
            " [0.25729826]\n",
            " [0.49921706]\n",
            " [0.19692037]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEnPKMmz5fo-",
        "outputId": "3eb7f53d-f946-4c84-9001-1fc6fdd0dfc1"
      },
      "source": [
        "y_pred_categorical1 = []\r\n",
        "for pred in y_pred1:\r\n",
        "  if pred > 0.5:\r\n",
        "    y_pred_categorical1.append(1)\r\n",
        "  else:\r\n",
        "    y_pred_categorical1.append(0)\r\n",
        "  \r\n",
        "\r\n",
        "print(y_pred_categorical1[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuJwdXGW5kzU",
        "outputId": "5991b315-55d0-450d-9d06-11256ebdd911"
      },
      "source": [
        "# measure accuracy\r\n",
        "accuracy = metrics.accuracy_score(y_val1, y_pred_categorical1)\r\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7064676616915423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z78eYca152_i",
        "outputId": "b63cb923-34b5-486c-b577-9eb941447bec"
      },
      "source": [
        "# Test predictions \r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df_test)}')\r\n",
        "\r\n",
        "X_test = df_test.drop(['Id'], axis=1)\r\n",
        "print(X_test.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 100\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      100 non-null    int64  \n",
            " 1   A2      100 non-null    int64  \n",
            " 2   A3      100 non-null    int64  \n",
            " 3   A4      100 non-null    int64  \n",
            " 4   A5      100 non-null    int64  \n",
            " 5   A6      100 non-null    float64\n",
            " 6   A7      100 non-null    float64\n",
            " 7   A8      100 non-null    int64  \n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 6.4 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21GFKDPF61QT",
        "outputId": "f361df28-7510-4a78-a89f-1d030792ec3e"
      },
      "source": [
        "test_pred = model1.predict(X_test)\r\n",
        "print(test_pred)\r\n",
        "\r\n",
        "test_pred_categorical = [1 if pred > 0.5 else 0 for pred in test_pred]\r\n",
        "print(test_pred_categorical)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.1670500e-01]\n",
            " [4.0108013e-01]\n",
            " [5.5382913e-01]\n",
            " [3.6843187e-01]\n",
            " [7.4215233e-02]\n",
            " [3.1066418e-01]\n",
            " [3.8011372e-02]\n",
            " [8.7752426e-01]\n",
            " [3.6958769e-01]\n",
            " [3.3615547e-01]\n",
            " [5.8491218e-01]\n",
            " [5.1153076e-01]\n",
            " [1.9247583e-01]\n",
            " [6.8173057e-01]\n",
            " [2.2306883e-01]\n",
            " [4.2488885e-01]\n",
            " [2.1788073e-01]\n",
            " [5.6389308e-01]\n",
            " [4.4475320e-01]\n",
            " [4.2440104e-01]\n",
            " [5.8358949e-01]\n",
            " [4.3531960e-01]\n",
            " [2.7281338e-01]\n",
            " [4.1215789e-01]\n",
            " [2.3370531e-01]\n",
            " [5.0952250e-01]\n",
            " [2.9193351e-01]\n",
            " [6.9836164e-01]\n",
            " [3.7749407e-01]\n",
            " [6.7842388e-01]\n",
            " [2.5988436e-01]\n",
            " [5.0237584e-01]\n",
            " [5.0591540e-01]\n",
            " [2.6176292e-01]\n",
            " [4.9230459e-01]\n",
            " [7.2806209e-02]\n",
            " [2.5834864e-01]\n",
            " [1.5262809e-01]\n",
            " [2.2357702e-04]\n",
            " [4.6244460e-01]\n",
            " [3.7376133e-01]\n",
            " [3.8505986e-01]\n",
            " [6.7009068e-01]\n",
            " [5.8048785e-02]\n",
            " [5.1456678e-01]\n",
            " [5.6728077e-01]\n",
            " [2.6953053e-01]\n",
            " [7.1896064e-01]\n",
            " [6.4362508e-01]\n",
            " [2.0246115e-01]\n",
            " [6.0327101e-01]\n",
            " [1.8403277e-01]\n",
            " [6.9309115e-02]\n",
            " [5.7909638e-01]\n",
            " [4.0243250e-01]\n",
            " [2.0683786e-01]\n",
            " [1.6896915e-01]\n",
            " [4.2605686e-01]\n",
            " [4.2179465e-01]\n",
            " [4.6230161e-01]\n",
            " [5.6287014e-01]\n",
            " [3.4256312e-01]\n",
            " [2.2026658e-01]\n",
            " [3.8032386e-01]\n",
            " [2.8575176e-01]\n",
            " [5.4433501e-01]\n",
            " [1.8875256e-01]\n",
            " [4.5557112e-01]\n",
            " [2.9351765e-01]\n",
            " [9.2710763e-02]\n",
            " [3.4757781e-01]\n",
            " [2.4648431e-01]\n",
            " [4.3660468e-01]\n",
            " [3.1674916e-01]\n",
            " [3.1918627e-01]\n",
            " [3.7716168e-01]\n",
            " [4.8513234e-01]\n",
            " [3.7203610e-01]\n",
            " [4.2345315e-01]\n",
            " [9.6200436e-02]\n",
            " [6.0031468e-01]\n",
            " [5.2567148e-01]\n",
            " [4.7512159e-01]\n",
            " [1.9095862e-01]\n",
            " [3.5676733e-01]\n",
            " [6.7962736e-01]\n",
            " [5.0844365e-01]\n",
            " [2.4032232e-01]\n",
            " [2.9885677e-01]\n",
            " [3.3573624e-01]\n",
            " [3.2338911e-01]\n",
            " [2.4974224e-01]\n",
            " [8.4557861e-02]\n",
            " [7.0458645e-01]\n",
            " [2.6381627e-01]\n",
            " [6.5710878e-01]\n",
            " [4.1373497e-01]\n",
            " [3.6964214e-01]\n",
            " [2.4133831e-01]\n",
            " [2.1269867e-01]]\n",
            "[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FGWgLUWExFX"
      },
      "source": [
        "**Model Two** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O6zC88gE1aT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650c3a63-1d1b-413d-e483-16c99b066f0b"
      },
      "source": [
        "#Building model Two\r\n",
        "\r\n",
        "# define the keras model\r\n",
        "model2 = Sequential()\r\n",
        "model2.add(Dense(64, input_dim=8, activation='relu')) #Defining our hidden layer - adding the layers to the model, a dence layer, 64 neurons, we selected 8 features so 8 input dimentions .\r\n",
        "model2.add(Dense(8, activation='relu')) #second hidden layer\r\n",
        "#using relu for hidden layers not for output layers \r\n",
        "model2.add(Dense(1, activation='sigmoid')) #creating our output layer with one neurone \r\n",
        "\r\n",
        "model2.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,105\n",
            "Trainable params: 1,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLAD4AP3HJ3O"
      },
      "source": [
        "# compile the keras model\r\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGRd0NmRHVnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc1b5a7-bedd-4cd9-8c54-f847a2c47fbc"
      },
      "source": [
        "#model2.fit(X_train1, y_train1, batch_size=60, epochs=70, validation_data=(X_val1, y_val1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 6.1700 - accuracy: 0.6023 - val_loss: 3.7457 - val_accuracy: 0.3582\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4139 - accuracy: 0.4105 - val_loss: 2.3722 - val_accuracy: 0.4776\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3987 - accuracy: 0.5652 - val_loss: 2.0555 - val_accuracy: 0.6020\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.5401 - accuracy: 0.5865 - val_loss: 1.6809 - val_accuracy: 0.4129\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4902 - accuracy: 0.5244 - val_loss: 1.4491 - val_accuracy: 0.6020\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2123 - accuracy: 0.6115 - val_loss: 1.1655 - val_accuracy: 0.4826\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1113 - accuracy: 0.5370 - val_loss: 1.0525 - val_accuracy: 0.5871\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9419 - accuracy: 0.6049 - val_loss: 1.0188 - val_accuracy: 0.6169\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9279 - accuracy: 0.5964 - val_loss: 0.9257 - val_accuracy: 0.6169\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8563 - accuracy: 0.6070 - val_loss: 0.8825 - val_accuracy: 0.6219\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7649 - accuracy: 0.6151 - val_loss: 0.8256 - val_accuracy: 0.6269\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7409 - accuracy: 0.6302 - val_loss: 0.8005 - val_accuracy: 0.6020\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7741 - accuracy: 0.6137 - val_loss: 0.7527 - val_accuracy: 0.6368\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6794 - accuracy: 0.6626 - val_loss: 0.7320 - val_accuracy: 0.5871\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7100 - accuracy: 0.5976 - val_loss: 0.7154 - val_accuracy: 0.6219\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6383 - accuracy: 0.6900 - val_loss: 0.6940 - val_accuracy: 0.6070\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6646 - accuracy: 0.6322 - val_loss: 0.6844 - val_accuracy: 0.6269\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.6560 - val_loss: 0.6764 - val_accuracy: 0.5970\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6327 - accuracy: 0.6383 - val_loss: 0.6502 - val_accuracy: 0.6368\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.7042 - val_loss: 0.6337 - val_accuracy: 0.6219\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6373 - accuracy: 0.6515 - val_loss: 0.6294 - val_accuracy: 0.6219\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.6658 - val_loss: 0.6286 - val_accuracy: 0.6368\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5665 - accuracy: 0.7311 - val_loss: 0.6026 - val_accuracy: 0.6716\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.6898 - val_loss: 0.6083 - val_accuracy: 0.6517\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.6864 - val_loss: 0.5997 - val_accuracy: 0.6816\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.7112 - val_loss: 0.6346 - val_accuracy: 0.6468\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.6496 - val_loss: 0.6105 - val_accuracy: 0.6517\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.6449 - val_loss: 0.5825 - val_accuracy: 0.6766\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5877 - accuracy: 0.7228 - val_loss: 0.5889 - val_accuracy: 0.6567\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.7352 - val_loss: 0.5807 - val_accuracy: 0.6915\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.7062 - val_loss: 0.5841 - val_accuracy: 0.6816\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5749 - accuracy: 0.6867 - val_loss: 0.5790 - val_accuracy: 0.6915\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5755 - accuracy: 0.7145 - val_loss: 0.5782 - val_accuracy: 0.6915\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5578 - accuracy: 0.7173 - val_loss: 0.5781 - val_accuracy: 0.6965\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.7078 - val_loss: 0.5795 - val_accuracy: 0.6766\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.7207 - val_loss: 0.5728 - val_accuracy: 0.7164\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7014 - val_loss: 0.5736 - val_accuracy: 0.6915\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.7418 - val_loss: 0.5687 - val_accuracy: 0.7065\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.6989 - val_loss: 0.5928 - val_accuracy: 0.6617\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5900 - accuracy: 0.7136 - val_loss: 0.5604 - val_accuracy: 0.7264\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5526 - accuracy: 0.7157 - val_loss: 0.5686 - val_accuracy: 0.7214\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7108 - val_loss: 0.5597 - val_accuracy: 0.7164\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.7158 - val_loss: 0.5664 - val_accuracy: 0.7164\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5467 - accuracy: 0.7104 - val_loss: 0.5654 - val_accuracy: 0.7164\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5369 - accuracy: 0.7519 - val_loss: 0.5826 - val_accuracy: 0.7015\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5634 - accuracy: 0.7177 - val_loss: 0.5852 - val_accuracy: 0.6866\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.7171 - val_loss: 0.5672 - val_accuracy: 0.7214\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5542 - accuracy: 0.7282 - val_loss: 0.5920 - val_accuracy: 0.7065\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.7202 - val_loss: 0.5609 - val_accuracy: 0.7015\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.7360 - val_loss: 0.5595 - val_accuracy: 0.7313\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.7069 - val_loss: 0.5542 - val_accuracy: 0.7313\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.7389 - val_loss: 0.5662 - val_accuracy: 0.7114\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5549 - accuracy: 0.7154 - val_loss: 0.6062 - val_accuracy: 0.6667\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5560 - accuracy: 0.7258 - val_loss: 0.5976 - val_accuracy: 0.6716\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5576 - accuracy: 0.7207 - val_loss: 0.5836 - val_accuracy: 0.7015\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5427 - accuracy: 0.7359 - val_loss: 0.5752 - val_accuracy: 0.7214\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5353 - accuracy: 0.7013 - val_loss: 0.6080 - val_accuracy: 0.6866\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.7199 - val_loss: 0.5595 - val_accuracy: 0.7065\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7180 - val_loss: 0.5929 - val_accuracy: 0.7114\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5564 - accuracy: 0.7167 - val_loss: 0.5667 - val_accuracy: 0.7015\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5478 - accuracy: 0.6880 - val_loss: 0.5666 - val_accuracy: 0.7264\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5447 - accuracy: 0.7242 - val_loss: 0.6124 - val_accuracy: 0.6965\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5486 - accuracy: 0.7019 - val_loss: 0.5915 - val_accuracy: 0.6866\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7373 - val_loss: 0.5550 - val_accuracy: 0.7413\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7258 - val_loss: 0.5598 - val_accuracy: 0.7363\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5223 - accuracy: 0.7316 - val_loss: 0.5514 - val_accuracy: 0.7214\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.7514 - val_loss: 0.5650 - val_accuracy: 0.7214\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5290 - accuracy: 0.7279 - val_loss: 0.5540 - val_accuracy: 0.7313\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7340 - val_loss: 0.5510 - val_accuracy: 0.7463\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.7432 - val_loss: 0.5647 - val_accuracy: 0.7363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac24ea6be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwQpuxUHgNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b2648d-1e84-4f02-be85-4c945ce6acc8"
      },
      "source": [
        "model2.fit(X_train1, y_train1, batch_size=100, epochs=70, validation_data=(X_val1, y_val1)) #Optimum model "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "5/5 [==============================] - 1s 73ms/step - loss: 3.3799 - accuracy: 0.5892 - val_loss: 2.6843 - val_accuracy: 0.5174\n",
            "Epoch 2/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2144 - accuracy: 0.5139 - val_loss: 1.5292 - val_accuracy: 0.6318\n",
            "Epoch 3/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.7470 - accuracy: 0.5557 - val_loss: 1.2471 - val_accuracy: 0.7015\n",
            "Epoch 4/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3687 - accuracy: 0.5707 - val_loss: 1.2333 - val_accuracy: 0.6816\n",
            "Epoch 5/70\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 1.3139 - accuracy: 0.6342 - val_loss: 1.1021 - val_accuracy: 0.6866\n",
            "Epoch 6/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2641 - accuracy: 0.6400 - val_loss: 0.9088 - val_accuracy: 0.6667\n",
            "Epoch 7/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0520 - accuracy: 0.6289 - val_loss: 0.8595 - val_accuracy: 0.6766\n",
            "Epoch 8/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8423 - accuracy: 0.6517 - val_loss: 0.8397 - val_accuracy: 0.6766\n",
            "Epoch 9/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8048 - accuracy: 0.6461 - val_loss: 0.7722 - val_accuracy: 0.6418\n",
            "Epoch 10/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6847 - accuracy: 0.6534 - val_loss: 0.7480 - val_accuracy: 0.6219\n",
            "Epoch 11/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6806 - accuracy: 0.6575 - val_loss: 0.7450 - val_accuracy: 0.6119\n",
            "Epoch 12/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6598 - accuracy: 0.6426 - val_loss: 0.7270 - val_accuracy: 0.6169\n",
            "Epoch 13/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7164 - accuracy: 0.6287 - val_loss: 0.6899 - val_accuracy: 0.6169\n",
            "Epoch 14/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6192 - accuracy: 0.6562 - val_loss: 0.7055 - val_accuracy: 0.6368\n",
            "Epoch 15/70\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6261 - accuracy: 0.7053 - val_loss: 0.6322 - val_accuracy: 0.6617\n",
            "Epoch 16/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6450 - accuracy: 0.6724 - val_loss: 0.6694 - val_accuracy: 0.6816\n",
            "Epoch 17/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6474 - accuracy: 0.6429 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
            "Epoch 18/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5773 - accuracy: 0.7110 - val_loss: 0.6249 - val_accuracy: 0.6517\n",
            "Epoch 19/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5893 - accuracy: 0.7006 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
            "Epoch 20/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6045 - accuracy: 0.6908 - val_loss: 0.6108 - val_accuracy: 0.6816\n",
            "Epoch 21/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5933 - accuracy: 0.7150 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
            "Epoch 22/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5893 - accuracy: 0.7076 - val_loss: 0.6126 - val_accuracy: 0.6816\n",
            "Epoch 23/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5892 - accuracy: 0.7070 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
            "Epoch 24/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.7031 - val_loss: 0.5937 - val_accuracy: 0.6965\n",
            "Epoch 25/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6065 - accuracy: 0.7189 - val_loss: 0.6509 - val_accuracy: 0.6617\n",
            "Epoch 26/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5689 - accuracy: 0.6815 - val_loss: 0.6591 - val_accuracy: 0.6766\n",
            "Epoch 27/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6028 - accuracy: 0.6985 - val_loss: 0.5831 - val_accuracy: 0.6915\n",
            "Epoch 28/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5812 - accuracy: 0.7182 - val_loss: 0.6461 - val_accuracy: 0.6816\n",
            "Epoch 29/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5944 - accuracy: 0.6513 - val_loss: 0.6204 - val_accuracy: 0.6866\n",
            "Epoch 30/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5917 - accuracy: 0.6899 - val_loss: 0.5748 - val_accuracy: 0.6965\n",
            "Epoch 31/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5824 - accuracy: 0.7266 - val_loss: 0.6615 - val_accuracy: 0.6766\n",
            "Epoch 32/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5945 - accuracy: 0.7070 - val_loss: 0.5790 - val_accuracy: 0.7015\n",
            "Epoch 33/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5840 - accuracy: 0.6732 - val_loss: 0.5996 - val_accuracy: 0.7015\n",
            "Epoch 34/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5450 - accuracy: 0.7577 - val_loss: 0.5810 - val_accuracy: 0.7065\n",
            "Epoch 35/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5401 - accuracy: 0.7350 - val_loss: 0.6384 - val_accuracy: 0.6567\n",
            "Epoch 36/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5737 - accuracy: 0.6838 - val_loss: 0.5980 - val_accuracy: 0.7015\n",
            "Epoch 37/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5295 - accuracy: 0.7450 - val_loss: 0.5640 - val_accuracy: 0.7313\n",
            "Epoch 38/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5422 - accuracy: 0.7446 - val_loss: 0.6003 - val_accuracy: 0.7114\n",
            "Epoch 39/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5538 - accuracy: 0.7053 - val_loss: 0.5778 - val_accuracy: 0.7015\n",
            "Epoch 40/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5697 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.6965\n",
            "Epoch 41/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5423 - accuracy: 0.7600 - val_loss: 0.5927 - val_accuracy: 0.7363\n",
            "Epoch 42/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5505 - accuracy: 0.7135 - val_loss: 0.5802 - val_accuracy: 0.7065\n",
            "Epoch 43/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5613 - accuracy: 0.7395 - val_loss: 0.5756 - val_accuracy: 0.7114\n",
            "Epoch 44/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5151 - accuracy: 0.7492 - val_loss: 0.5962 - val_accuracy: 0.7463\n",
            "Epoch 45/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5378 - accuracy: 0.7367 - val_loss: 0.5733 - val_accuracy: 0.7065\n",
            "Epoch 46/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5360 - accuracy: 0.7344 - val_loss: 0.5842 - val_accuracy: 0.6965\n",
            "Epoch 47/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5294 - accuracy: 0.7492 - val_loss: 0.5741 - val_accuracy: 0.7114\n",
            "Epoch 48/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5619 - accuracy: 0.7372 - val_loss: 0.6315 - val_accuracy: 0.7114\n",
            "Epoch 49/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5611 - accuracy: 0.7500 - val_loss: 0.6154 - val_accuracy: 0.6766\n",
            "Epoch 50/70\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5369 - accuracy: 0.6998 - val_loss: 0.5885 - val_accuracy: 0.6816\n",
            "Epoch 51/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5633 - accuracy: 0.7227 - val_loss: 0.5815 - val_accuracy: 0.7214\n",
            "Epoch 52/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5336 - accuracy: 0.7328 - val_loss: 0.6975 - val_accuracy: 0.6070\n",
            "Epoch 53/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5567 - accuracy: 0.7133 - val_loss: 0.6981 - val_accuracy: 0.6766\n",
            "Epoch 54/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6369 - accuracy: 0.6999 - val_loss: 0.5720 - val_accuracy: 0.7114\n",
            "Epoch 55/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5601 - accuracy: 0.7042 - val_loss: 0.6711 - val_accuracy: 0.6667\n",
            "Epoch 56/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5898 - accuracy: 0.6894 - val_loss: 0.7445 - val_accuracy: 0.6816\n",
            "Epoch 57/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.6951 - val_loss: 0.7628 - val_accuracy: 0.5970\n",
            "Epoch 58/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.6350 - val_loss: 0.6013 - val_accuracy: 0.6965\n",
            "Epoch 59/70\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.5411 - accuracy: 0.7034 - val_loss: 0.5617 - val_accuracy: 0.7114\n",
            "Epoch 60/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5770 - accuracy: 0.7225 - val_loss: 0.6348 - val_accuracy: 0.7015\n",
            "Epoch 61/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5424 - accuracy: 0.7267 - val_loss: 0.5731 - val_accuracy: 0.7214\n",
            "Epoch 62/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5005 - accuracy: 0.7549 - val_loss: 0.5686 - val_accuracy: 0.7015\n",
            "Epoch 63/70\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5522 - accuracy: 0.7299 - val_loss: 0.5968 - val_accuracy: 0.7313\n",
            "Epoch 64/70\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5400 - accuracy: 0.7259 - val_loss: 0.5833 - val_accuracy: 0.7114\n",
            "Epoch 65/70\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5054 - accuracy: 0.7524 - val_loss: 0.5729 - val_accuracy: 0.7015\n",
            "Epoch 66/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.7262 - val_loss: 0.5871 - val_accuracy: 0.7463\n",
            "Epoch 67/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5216 - accuracy: 0.7455 - val_loss: 0.5977 - val_accuracy: 0.7264\n",
            "Epoch 68/70\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5133 - accuracy: 0.7429 - val_loss: 0.5720 - val_accuracy: 0.7114\n",
            "Epoch 69/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5331 - accuracy: 0.7462 - val_loss: 0.5986 - val_accuracy: 0.7264\n",
            "Epoch 70/70\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5272 - accuracy: 0.7273 - val_loss: 0.5843 - val_accuracy: 0.7114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d6b836518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KkNbgG1Hvdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b94e9bc-1a6d-4f76-a77b-e5df1277557a"
      },
      "source": [
        "#model2.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.4892 - accuracy: 0.7473 - val_loss: 0.6024 - val_accuracy: 0.7164\n",
            "Epoch 2/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7216 - val_loss: 0.6033 - val_accuracy: 0.6915\n",
            "Epoch 3/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7473 - val_loss: 0.6226 - val_accuracy: 0.6816\n",
            "Epoch 4/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.7430 - val_loss: 0.6871 - val_accuracy: 0.6517\n",
            "Epoch 5/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7516 - val_loss: 0.6022 - val_accuracy: 0.6965\n",
            "Epoch 6/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7409 - val_loss: 0.5550 - val_accuracy: 0.7264\n",
            "Epoch 7/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7345 - val_loss: 0.5686 - val_accuracy: 0.7065\n",
            "Epoch 8/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7409 - val_loss: 0.6440 - val_accuracy: 0.6716\n",
            "Epoch 9/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7109 - val_loss: 0.5669 - val_accuracy: 0.7264\n",
            "Epoch 10/60\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.7709 - val_loss: 0.5844 - val_accuracy: 0.6965\n",
            "Epoch 11/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7452 - val_loss: 0.5881 - val_accuracy: 0.7065\n",
            "Epoch 12/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7430 - val_loss: 0.5446 - val_accuracy: 0.7512\n",
            "Epoch 13/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7495 - val_loss: 0.6340 - val_accuracy: 0.6915\n",
            "Epoch 14/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7409 - val_loss: 0.5577 - val_accuracy: 0.7164\n",
            "Epoch 15/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7473 - val_loss: 0.5612 - val_accuracy: 0.7363\n",
            "Epoch 16/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7602 - val_loss: 0.6142 - val_accuracy: 0.6617\n",
            "Epoch 17/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.7495 - val_loss: 0.6438 - val_accuracy: 0.6766\n",
            "Epoch 18/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7559 - val_loss: 0.6252 - val_accuracy: 0.6716\n",
            "Epoch 19/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7173 - val_loss: 0.6229 - val_accuracy: 0.6915\n",
            "Epoch 20/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7559 - val_loss: 0.5815 - val_accuracy: 0.7164\n",
            "Epoch 21/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7409 - val_loss: 0.5981 - val_accuracy: 0.6965\n",
            "Epoch 22/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7473 - val_loss: 0.5914 - val_accuracy: 0.7114\n",
            "Epoch 23/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7773 - val_loss: 0.5757 - val_accuracy: 0.7164\n",
            "Epoch 24/60\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.4693 - accuracy: 0.7430 - val_loss: 0.6074 - val_accuracy: 0.6965\n",
            "Epoch 25/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7430 - val_loss: 0.5804 - val_accuracy: 0.7065\n",
            "Epoch 26/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7366 - val_loss: 0.5525 - val_accuracy: 0.7114\n",
            "Epoch 27/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7302 - val_loss: 0.6700 - val_accuracy: 0.6816\n",
            "Epoch 28/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7216 - val_loss: 0.5869 - val_accuracy: 0.6965\n",
            "Epoch 29/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7516 - val_loss: 0.5757 - val_accuracy: 0.7313\n",
            "Epoch 30/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7709 - val_loss: 0.6248 - val_accuracy: 0.6965\n",
            "Epoch 31/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.7580 - val_loss: 0.6076 - val_accuracy: 0.6965\n",
            "Epoch 32/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7559 - val_loss: 0.5586 - val_accuracy: 0.7313\n",
            "Epoch 33/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7580 - val_loss: 0.6029 - val_accuracy: 0.7015\n",
            "Epoch 34/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7473 - val_loss: 0.5683 - val_accuracy: 0.7363\n",
            "Epoch 35/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7901 - val_loss: 0.5795 - val_accuracy: 0.7214\n",
            "Epoch 36/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7730 - val_loss: 0.5656 - val_accuracy: 0.7264\n",
            "Epoch 37/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7730 - val_loss: 0.5699 - val_accuracy: 0.7264\n",
            "Epoch 38/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7495 - val_loss: 0.5523 - val_accuracy: 0.7264\n",
            "Epoch 39/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7645 - val_loss: 0.5590 - val_accuracy: 0.7065\n",
            "Epoch 40/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7452 - val_loss: 0.5619 - val_accuracy: 0.7463\n",
            "Epoch 41/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7709 - val_loss: 0.5586 - val_accuracy: 0.7363\n",
            "Epoch 42/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7623 - val_loss: 0.6275 - val_accuracy: 0.7015\n",
            "Epoch 43/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.7709 - val_loss: 0.5508 - val_accuracy: 0.7363\n",
            "Epoch 44/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.7773 - val_loss: 0.5687 - val_accuracy: 0.7214\n",
            "Epoch 45/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7495 - val_loss: 0.6006 - val_accuracy: 0.7214\n",
            "Epoch 46/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7687 - val_loss: 0.5766 - val_accuracy: 0.7114\n",
            "Epoch 47/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7623 - val_loss: 0.5601 - val_accuracy: 0.7512\n",
            "Epoch 48/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7602 - val_loss: 0.6047 - val_accuracy: 0.6965\n",
            "Epoch 49/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7752 - val_loss: 0.6151 - val_accuracy: 0.6716\n",
            "Epoch 50/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7580 - val_loss: 0.6234 - val_accuracy: 0.6965\n",
            "Epoch 51/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7645 - val_loss: 0.5456 - val_accuracy: 0.7413\n",
            "Epoch 52/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7666 - val_loss: 0.5513 - val_accuracy: 0.7264\n",
            "Epoch 53/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7516 - val_loss: 0.5608 - val_accuracy: 0.7214\n",
            "Epoch 54/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7602 - val_loss: 0.5809 - val_accuracy: 0.7313\n",
            "Epoch 55/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7366 - val_loss: 0.6050 - val_accuracy: 0.7015\n",
            "Epoch 56/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7794 - val_loss: 0.5499 - val_accuracy: 0.7363\n",
            "Epoch 57/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7687 - val_loss: 0.5943 - val_accuracy: 0.7164\n",
            "Epoch 58/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7602 - val_loss: 0.6419 - val_accuracy: 0.6617\n",
            "Epoch 59/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7580 - val_loss: 0.5703 - val_accuracy: 0.7413\n",
            "Epoch 60/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7602 - val_loss: 0.5573 - val_accuracy: 0.7214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac22767dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LmNwjFdkV5l",
        "outputId": "045e3152-76f6-4cc0-a078-18d96169c012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get model predictions for validation data\r\n",
        "y_pred2 = model2.predict(X_val1)\r\n",
        "print(y_pred2[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.4061700e-01]\n",
            " [3.5600543e-02]\n",
            " [3.9253354e-01]\n",
            " [2.8376374e-01]\n",
            " [7.4988711e-01]\n",
            " [2.2759652e-07]\n",
            " [6.1351818e-01]\n",
            " [1.7568830e-01]\n",
            " [6.1033583e-01]\n",
            " [3.6573350e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlMMwpLKlHO1",
        "outputId": "1bbd7c41-6ec1-4746-98b0-9fc17f664f21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_categorical2 = []\r\n",
        "for pred in y_pred2:\r\n",
        "  if pred > 0.5:\r\n",
        "    y_pred_categorical2.append(1)\r\n",
        "  else:\r\n",
        "    y_pred_categorical2.append(0)\r\n",
        "  \r\n",
        "\r\n",
        "print(y_pred_categorical2[:10])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ytjtLAlZce",
        "outputId": "f3800ce4-b3e2-46ef-d846-6920053fcfe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# measure accuracy\r\n",
        "accuracy = metrics.accuracy_score(y_val1, y_pred_categorical2)\r\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7114427860696517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEaSt-DXIF0O"
      },
      "source": [
        "Model **three**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYduXz-IIH9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510f770d-a493-42a2-cf3b-2d96c26fbd58"
      },
      "source": [
        "#Building model Three\r\n",
        "\r\n",
        "# define the keras model\r\n",
        "model3 = Sequential()\r\n",
        "model3.add(Dense(64, input_dim=8, activation='relu')) #Defining our hidden layer - adding the layers to the model, a dence layer, 64 neurons, we selected 8 features so 8 input dimentions .\r\n",
        "model3.add(Dense(8, activation='relu')) #second hidden layer\r\n",
        "model3.add(Dense(8, activation='relu')) #3rd hidden layer\r\n",
        "\r\n",
        "model3.add(Dense(8, activation='relu')) #4th hidden layer\r\n",
        "\r\n",
        "\r\n",
        "#using relu for hidden layers not for output layers \r\n",
        "model3.add(Dense(1, activation='sigmoid')) #creating our output layer with one neurone \r\n",
        "\r\n",
        "model3.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,249\n",
            "Trainable params: 1,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQY1IOf7IYL4"
      },
      "source": [
        "# compile the keras model\r\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsYGWxP-Iklr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae10fdd1-19c7-4146-bc6d-933e037dd7e3"
      },
      "source": [
        "#model3.fit(X_train1, y_train1, batch_size=60, epochs=70, validation_data=(X_val1, y_val1)) - The better one "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 12.1224 - accuracy: 0.6482 - val_loss: 5.7709 - val_accuracy: 0.6617\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2096 - accuracy: 0.6517 - val_loss: 3.2653 - val_accuracy: 0.5174\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.9699 - accuracy: 0.5145 - val_loss: 1.9802 - val_accuracy: 0.5124\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6022 - accuracy: 0.5509 - val_loss: 1.1803 - val_accuracy: 0.6368\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2775 - accuracy: 0.5720 - val_loss: 0.8644 - val_accuracy: 0.6716\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9087 - accuracy: 0.6497 - val_loss: 0.8870 - val_accuracy: 0.6468\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9764 - accuracy: 0.6351 - val_loss: 0.7945 - val_accuracy: 0.6418\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8565 - accuracy: 0.6394 - val_loss: 0.7373 - val_accuracy: 0.6667\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7794 - accuracy: 0.6364 - val_loss: 0.7122 - val_accuracy: 0.6816\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7018 - accuracy: 0.6488 - val_loss: 0.6972 - val_accuracy: 0.6716\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7260 - accuracy: 0.6288 - val_loss: 0.6831 - val_accuracy: 0.6716\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7087 - accuracy: 0.6303 - val_loss: 0.6618 - val_accuracy: 0.7065\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6558 - val_loss: 0.6541 - val_accuracy: 0.6617\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6584 - accuracy: 0.6444 - val_loss: 0.6415 - val_accuracy: 0.6716\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6173 - accuracy: 0.6467 - val_loss: 0.6297 - val_accuracy: 0.6617\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.6287 - val_loss: 0.6296 - val_accuracy: 0.6866\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6010 - accuracy: 0.6413 - val_loss: 0.6247 - val_accuracy: 0.6617\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6667 - val_loss: 0.6200 - val_accuracy: 0.6766\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6027 - accuracy: 0.6307 - val_loss: 0.6120 - val_accuracy: 0.6766\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5904 - accuracy: 0.6845 - val_loss: 0.6097 - val_accuracy: 0.6965\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.7013 - val_loss: 0.6164 - val_accuracy: 0.6716\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5632 - accuracy: 0.6679 - val_loss: 0.5999 - val_accuracy: 0.7015\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.6976 - val_loss: 0.5962 - val_accuracy: 0.6866\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.6934 - val_loss: 0.6152 - val_accuracy: 0.6915\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.6725 - val_loss: 0.5889 - val_accuracy: 0.6866\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5735 - accuracy: 0.7032 - val_loss: 0.6038 - val_accuracy: 0.7114\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7129 - val_loss: 0.5894 - val_accuracy: 0.7164\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5490 - accuracy: 0.7291 - val_loss: 0.6006 - val_accuracy: 0.7015\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5530 - accuracy: 0.6842 - val_loss: 0.5838 - val_accuracy: 0.7065\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5788 - accuracy: 0.6872 - val_loss: 0.5860 - val_accuracy: 0.7015\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5697 - accuracy: 0.6841 - val_loss: 0.5813 - val_accuracy: 0.7114\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5592 - accuracy: 0.7025 - val_loss: 0.6109 - val_accuracy: 0.7164\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5613 - accuracy: 0.7005 - val_loss: 0.5802 - val_accuracy: 0.7164\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7308 - val_loss: 0.5977 - val_accuracy: 0.7065\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7112 - val_loss: 0.5792 - val_accuracy: 0.7114\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.6997 - val_loss: 0.5917 - val_accuracy: 0.7015\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5611 - accuracy: 0.6945 - val_loss: 0.5838 - val_accuracy: 0.7114\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.6918 - val_loss: 0.5909 - val_accuracy: 0.7313\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7303 - val_loss: 0.5823 - val_accuracy: 0.7015\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5673 - accuracy: 0.6847 - val_loss: 0.6036 - val_accuracy: 0.7015\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7252 - val_loss: 0.5804 - val_accuracy: 0.7114\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5637 - accuracy: 0.7048 - val_loss: 0.6256 - val_accuracy: 0.6766\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5642 - accuracy: 0.7070 - val_loss: 0.5718 - val_accuracy: 0.7264\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5602 - accuracy: 0.7032 - val_loss: 0.6128 - val_accuracy: 0.7015\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5629 - accuracy: 0.7222 - val_loss: 0.5729 - val_accuracy: 0.7214\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5461 - accuracy: 0.6939 - val_loss: 0.5838 - val_accuracy: 0.7114\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.7174 - val_loss: 0.5866 - val_accuracy: 0.7264\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5657 - accuracy: 0.6810 - val_loss: 0.5738 - val_accuracy: 0.7313\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5324 - accuracy: 0.7148 - val_loss: 0.5809 - val_accuracy: 0.7264\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5146 - accuracy: 0.7274 - val_loss: 0.5781 - val_accuracy: 0.7214\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.6908 - val_loss: 0.5743 - val_accuracy: 0.7313\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.7033 - val_loss: 0.5699 - val_accuracy: 0.7214\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5269 - accuracy: 0.7317 - val_loss: 0.5768 - val_accuracy: 0.7164\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5400 - accuracy: 0.7132 - val_loss: 0.5818 - val_accuracy: 0.7214\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7067 - val_loss: 0.5698 - val_accuracy: 0.7164\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5310 - accuracy: 0.7278 - val_loss: 0.5920 - val_accuracy: 0.7114\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7162 - val_loss: 0.5718 - val_accuracy: 0.7463\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.7424 - val_loss: 0.5756 - val_accuracy: 0.7164\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5243 - accuracy: 0.7352 - val_loss: 0.5972 - val_accuracy: 0.7065\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7251 - val_loss: 0.5644 - val_accuracy: 0.7313\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5277 - accuracy: 0.7063 - val_loss: 0.5806 - val_accuracy: 0.7164\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5365 - accuracy: 0.7286 - val_loss: 0.5760 - val_accuracy: 0.7214\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7322 - val_loss: 0.5689 - val_accuracy: 0.7264\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5022 - accuracy: 0.7355 - val_loss: 0.5927 - val_accuracy: 0.7164\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.7320 - val_loss: 0.5702 - val_accuracy: 0.7264\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5195 - accuracy: 0.7248 - val_loss: 0.5927 - val_accuracy: 0.7214\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7337 - val_loss: 0.5721 - val_accuracy: 0.7264\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5402 - accuracy: 0.7007 - val_loss: 0.5785 - val_accuracy: 0.7264\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7480 - val_loss: 0.5930 - val_accuracy: 0.7114\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.7494 - val_loss: 0.5663 - val_accuracy: 0.7313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac216a97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0fsZM4ZIsNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2a7e0a-6509-4029-cfb1-fdc466a08449"
      },
      "source": [
        "#model3.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5329 - accuracy: 0.7195 - val_loss: 0.5806 - val_accuracy: 0.7264\n",
            "Epoch 2/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7345 - val_loss: 0.5938 - val_accuracy: 0.7015\n",
            "Epoch 3/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7430 - val_loss: 0.5636 - val_accuracy: 0.7463\n",
            "Epoch 4/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7238 - val_loss: 0.5591 - val_accuracy: 0.7463\n",
            "Epoch 5/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7452 - val_loss: 0.6481 - val_accuracy: 0.6766\n",
            "Epoch 6/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7302 - val_loss: 0.5675 - val_accuracy: 0.7363\n",
            "Epoch 7/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7066 - val_loss: 0.5736 - val_accuracy: 0.7114\n",
            "Epoch 8/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.7109 - val_loss: 0.5673 - val_accuracy: 0.7363\n",
            "Epoch 9/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7323 - val_loss: 0.5561 - val_accuracy: 0.7363\n",
            "Epoch 10/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7259 - val_loss: 0.5759 - val_accuracy: 0.7214\n",
            "Epoch 11/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.7259 - val_loss: 0.5704 - val_accuracy: 0.7413\n",
            "Epoch 12/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7452 - val_loss: 0.5691 - val_accuracy: 0.7463\n",
            "Epoch 13/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7281 - val_loss: 0.5756 - val_accuracy: 0.7413\n",
            "Epoch 14/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7430 - val_loss: 0.5588 - val_accuracy: 0.7413\n",
            "Epoch 15/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7537 - val_loss: 0.6594 - val_accuracy: 0.6766\n",
            "Epoch 16/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7195 - val_loss: 0.5838 - val_accuracy: 0.7214\n",
            "Epoch 17/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7388 - val_loss: 0.5752 - val_accuracy: 0.7264\n",
            "Epoch 18/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5425 - accuracy: 0.7216 - val_loss: 0.6276 - val_accuracy: 0.6816\n",
            "Epoch 19/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7281 - val_loss: 0.6128 - val_accuracy: 0.7015\n",
            "Epoch 20/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7002 - val_loss: 0.5488 - val_accuracy: 0.7512\n",
            "Epoch 21/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5247 - accuracy: 0.7366 - val_loss: 0.5572 - val_accuracy: 0.7562\n",
            "Epoch 22/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7537 - val_loss: 0.5877 - val_accuracy: 0.7065\n",
            "Epoch 23/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7516 - val_loss: 0.5673 - val_accuracy: 0.7413\n",
            "Epoch 24/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7623 - val_loss: 0.5798 - val_accuracy: 0.7313\n",
            "Epoch 25/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7709 - val_loss: 0.5662 - val_accuracy: 0.7512\n",
            "Epoch 26/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7495 - val_loss: 0.5678 - val_accuracy: 0.7363\n",
            "Epoch 27/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7409 - val_loss: 0.5881 - val_accuracy: 0.7214\n",
            "Epoch 28/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7495 - val_loss: 0.6209 - val_accuracy: 0.6915\n",
            "Epoch 29/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7409 - val_loss: 0.5802 - val_accuracy: 0.7264\n",
            "Epoch 30/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7495 - val_loss: 0.5636 - val_accuracy: 0.7264\n",
            "Epoch 31/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7430 - val_loss: 0.5611 - val_accuracy: 0.7363\n",
            "Epoch 32/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7366 - val_loss: 0.6044 - val_accuracy: 0.7164\n",
            "Epoch 33/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7516 - val_loss: 0.5546 - val_accuracy: 0.7363\n",
            "Epoch 34/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7559 - val_loss: 0.6056 - val_accuracy: 0.7015\n",
            "Epoch 35/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7452 - val_loss: 0.5830 - val_accuracy: 0.7463\n",
            "Epoch 36/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7752 - val_loss: 0.5567 - val_accuracy: 0.7313\n",
            "Epoch 37/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7430 - val_loss: 0.5578 - val_accuracy: 0.7313\n",
            "Epoch 38/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7216 - val_loss: 0.5615 - val_accuracy: 0.7612\n",
            "Epoch 39/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7580 - val_loss: 0.5757 - val_accuracy: 0.7313\n",
            "Epoch 40/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.7559 - val_loss: 0.5518 - val_accuracy: 0.7363\n",
            "Epoch 41/60\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.4959 - accuracy: 0.7730 - val_loss: 0.5550 - val_accuracy: 0.7612\n",
            "Epoch 42/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7666 - val_loss: 0.5488 - val_accuracy: 0.7313\n",
            "Epoch 43/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7473 - val_loss: 0.5588 - val_accuracy: 0.7562\n",
            "Epoch 44/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7516 - val_loss: 0.6741 - val_accuracy: 0.6468\n",
            "Epoch 45/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7366 - val_loss: 0.5609 - val_accuracy: 0.7562\n",
            "Epoch 46/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7409 - val_loss: 0.5585 - val_accuracy: 0.7512\n",
            "Epoch 47/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7537 - val_loss: 0.5608 - val_accuracy: 0.7562\n",
            "Epoch 48/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7730 - val_loss: 0.5564 - val_accuracy: 0.7662\n",
            "Epoch 49/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7452 - val_loss: 0.6484 - val_accuracy: 0.7015\n",
            "Epoch 50/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7473 - val_loss: 0.5846 - val_accuracy: 0.7214\n",
            "Epoch 51/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7516 - val_loss: 0.5620 - val_accuracy: 0.7463\n",
            "Epoch 52/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7580 - val_loss: 0.5665 - val_accuracy: 0.7214\n",
            "Epoch 53/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7473 - val_loss: 0.6230 - val_accuracy: 0.7065\n",
            "Epoch 54/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7473 - val_loss: 0.5526 - val_accuracy: 0.7662\n",
            "Epoch 55/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7837 - val_loss: 0.5566 - val_accuracy: 0.7313\n",
            "Epoch 56/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7537 - val_loss: 0.6567 - val_accuracy: 0.6766\n",
            "Epoch 57/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7602 - val_loss: 0.5583 - val_accuracy: 0.7413\n",
            "Epoch 58/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7409 - val_loss: 0.5546 - val_accuracy: 0.7612\n",
            "Epoch 59/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7580 - val_loss: 0.5938 - val_accuracy: 0.7214\n",
            "Epoch 60/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7666 - val_loss: 0.5704 - val_accuracy: 0.7463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac2274de48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9aZuaA7JGFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c731b31-3aa9-4bdc-c255-c4a012ca7f87"
      },
      "source": [
        "#model3.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1)) #better one so far "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "10/10 [==============================] - 1s 23ms/step - loss: 3.7131 - accuracy: 0.6666 - val_loss: 0.9978 - val_accuracy: 0.6368\n",
            "Epoch 2/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8182 - accuracy: 0.6409 - val_loss: 0.6607 - val_accuracy: 0.6517\n",
            "Epoch 3/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.6728 - val_loss: 0.6799 - val_accuracy: 0.6517\n",
            "Epoch 4/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.6607 - val_loss: 0.6746 - val_accuracy: 0.6318\n",
            "Epoch 5/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.6683 - val_loss: 0.6653 - val_accuracy: 0.6468\n",
            "Epoch 6/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6312 - val_loss: 0.6612 - val_accuracy: 0.6468\n",
            "Epoch 7/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6761 - val_loss: 0.6591 - val_accuracy: 0.6567\n",
            "Epoch 8/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.6720 - val_loss: 0.6491 - val_accuracy: 0.6617\n",
            "Epoch 9/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6146 - val_loss: 0.6512 - val_accuracy: 0.6567\n",
            "Epoch 10/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6460 - accuracy: 0.6441 - val_loss: 0.6490 - val_accuracy: 0.6716\n",
            "Epoch 11/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.6920 - val_loss: 0.6530 - val_accuracy: 0.6468\n",
            "Epoch 12/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6175 - accuracy: 0.6824 - val_loss: 0.6375 - val_accuracy: 0.6766\n",
            "Epoch 13/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.6807 - val_loss: 0.6257 - val_accuracy: 0.6716\n",
            "Epoch 14/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.6924 - val_loss: 0.6340 - val_accuracy: 0.6965\n",
            "Epoch 15/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6873 - val_loss: 0.6145 - val_accuracy: 0.7214\n",
            "Epoch 16/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.7311 - val_loss: 0.6269 - val_accuracy: 0.6915\n",
            "Epoch 17/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6052 - accuracy: 0.6732 - val_loss: 0.6223 - val_accuracy: 0.7164\n",
            "Epoch 18/60\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 0.5876 - accuracy: 0.7065 - val_loss: 0.6125 - val_accuracy: 0.7214\n",
            "Epoch 19/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.6838 - val_loss: 0.6142 - val_accuracy: 0.7114\n",
            "Epoch 20/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5722 - accuracy: 0.7250 - val_loss: 0.6197 - val_accuracy: 0.7015\n",
            "Epoch 21/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7251 - val_loss: 0.6238 - val_accuracy: 0.6965\n",
            "Epoch 22/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5951 - accuracy: 0.7215 - val_loss: 0.5958 - val_accuracy: 0.6965\n",
            "Epoch 23/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7342 - val_loss: 0.6251 - val_accuracy: 0.6816\n",
            "Epoch 24/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5719 - accuracy: 0.7362 - val_loss: 0.6081 - val_accuracy: 0.7264\n",
            "Epoch 25/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.7307 - val_loss: 0.6054 - val_accuracy: 0.7164\n",
            "Epoch 26/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.7470 - val_loss: 0.6001 - val_accuracy: 0.7313\n",
            "Epoch 27/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7384 - val_loss: 0.6052 - val_accuracy: 0.7214\n",
            "Epoch 28/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7202 - val_loss: 0.5895 - val_accuracy: 0.7363\n",
            "Epoch 29/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5380 - accuracy: 0.7499 - val_loss: 0.5969 - val_accuracy: 0.7214\n",
            "Epoch 30/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7588 - val_loss: 0.5914 - val_accuracy: 0.7264\n",
            "Epoch 31/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.7306 - val_loss: 0.6088 - val_accuracy: 0.6965\n",
            "Epoch 32/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5543 - accuracy: 0.7520 - val_loss: 0.6185 - val_accuracy: 0.6915\n",
            "Epoch 33/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.6862 - val_loss: 0.6225 - val_accuracy: 0.6816\n",
            "Epoch 34/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7509 - val_loss: 0.5815 - val_accuracy: 0.7065\n",
            "Epoch 35/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7413 - val_loss: 0.5887 - val_accuracy: 0.7164\n",
            "Epoch 36/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7790 - val_loss: 0.5956 - val_accuracy: 0.7114\n",
            "Epoch 37/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7301 - val_loss: 0.5921 - val_accuracy: 0.7214\n",
            "Epoch 38/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7618 - val_loss: 0.5984 - val_accuracy: 0.7114\n",
            "Epoch 39/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7468 - val_loss: 0.5761 - val_accuracy: 0.7363\n",
            "Epoch 40/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7416 - val_loss: 0.5878 - val_accuracy: 0.7164\n",
            "Epoch 41/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7460 - val_loss: 0.5700 - val_accuracy: 0.7363\n",
            "Epoch 42/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7482 - val_loss: 0.5833 - val_accuracy: 0.7114\n",
            "Epoch 43/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7451 - val_loss: 0.5930 - val_accuracy: 0.7065\n",
            "Epoch 44/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7290 - val_loss: 0.5783 - val_accuracy: 0.7313\n",
            "Epoch 45/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7328 - val_loss: 0.5719 - val_accuracy: 0.7463\n",
            "Epoch 46/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7267 - val_loss: 0.5753 - val_accuracy: 0.7363\n",
            "Epoch 47/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7657 - val_loss: 0.5934 - val_accuracy: 0.7015\n",
            "Epoch 48/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5307 - accuracy: 0.7192 - val_loss: 0.5672 - val_accuracy: 0.7463\n",
            "Epoch 49/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.7519 - val_loss: 0.5823 - val_accuracy: 0.7313\n",
            "Epoch 50/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7520 - val_loss: 0.5839 - val_accuracy: 0.7264\n",
            "Epoch 51/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7402 - val_loss: 0.5663 - val_accuracy: 0.7512\n",
            "Epoch 52/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7616 - val_loss: 0.5664 - val_accuracy: 0.7463\n",
            "Epoch 53/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7562 - val_loss: 0.5817 - val_accuracy: 0.7264\n",
            "Epoch 54/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7578 - val_loss: 0.5799 - val_accuracy: 0.7313\n",
            "Epoch 55/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7597 - val_loss: 0.5679 - val_accuracy: 0.7463\n",
            "Epoch 56/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7623 - val_loss: 0.5622 - val_accuracy: 0.7164\n",
            "Epoch 57/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7372 - val_loss: 0.5844 - val_accuracy: 0.7214\n",
            "Epoch 58/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7612 - val_loss: 0.5747 - val_accuracy: 0.7463\n",
            "Epoch 59/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5091 - accuracy: 0.7671 - val_loss: 0.5595 - val_accuracy: 0.7114\n",
            "Epoch 60/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5595 - accuracy: 0.7093 - val_loss: 0.5784 - val_accuracy: 0.7363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac215c82e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWxpEZGtJiu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458763ee-9294-47f5-cfdc-c0928d7a841d"
      },
      "source": [
        "model3.fit(X_train1, y_train1, batch_size=60, epochs=70, validation_data=(X_val1, y_val1)) #better one so far "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 1.2280 - accuracy: 0.5676 - val_loss: 0.8210 - val_accuracy: 0.4179\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.5632 - val_loss: 0.7184 - val_accuracy: 0.6567\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7200 - accuracy: 0.6388 - val_loss: 0.6852 - val_accuracy: 0.5672\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.5611 - val_loss: 0.6583 - val_accuracy: 0.6617\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.6770 - val_loss: 0.6539 - val_accuracy: 0.6517\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6255 - accuracy: 0.6773 - val_loss: 0.6417 - val_accuracy: 0.6816\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.6960 - val_loss: 0.6274 - val_accuracy: 0.7015\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6443 - accuracy: 0.6540 - val_loss: 0.6172 - val_accuracy: 0.6915\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6095 - accuracy: 0.7050 - val_loss: 0.6143 - val_accuracy: 0.6816\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6176 - accuracy: 0.6520 - val_loss: 0.6080 - val_accuracy: 0.6915\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.6806 - val_loss: 0.6008 - val_accuracy: 0.6915\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.7042 - val_loss: 0.5964 - val_accuracy: 0.6766\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6689 - val_loss: 0.5925 - val_accuracy: 0.6866\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.6568 - val_loss: 0.5874 - val_accuracy: 0.7114\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6071 - accuracy: 0.6715 - val_loss: 0.5861 - val_accuracy: 0.6965\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5930 - accuracy: 0.6908 - val_loss: 0.5912 - val_accuracy: 0.6766\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.6847 - val_loss: 0.5813 - val_accuracy: 0.7065\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.6819 - val_loss: 0.5791 - val_accuracy: 0.7164\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5850 - accuracy: 0.6850 - val_loss: 0.5814 - val_accuracy: 0.6965\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5869 - accuracy: 0.6620 - val_loss: 0.5821 - val_accuracy: 0.7065\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.7127 - val_loss: 0.5799 - val_accuracy: 0.6816\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5861 - accuracy: 0.6867 - val_loss: 0.5758 - val_accuracy: 0.7065\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5852 - accuracy: 0.7047 - val_loss: 0.5756 - val_accuracy: 0.6965\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.6752 - val_loss: 0.5718 - val_accuracy: 0.7065\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5624 - accuracy: 0.6916 - val_loss: 0.5853 - val_accuracy: 0.7065\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5673 - accuracy: 0.7139 - val_loss: 0.5695 - val_accuracy: 0.7065\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5582 - accuracy: 0.7272 - val_loss: 0.5697 - val_accuracy: 0.7065\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5640 - accuracy: 0.6990 - val_loss: 0.5980 - val_accuracy: 0.7015\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5737 - accuracy: 0.7061 - val_loss: 0.5724 - val_accuracy: 0.7214\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5691 - accuracy: 0.7094 - val_loss: 0.5700 - val_accuracy: 0.7164\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.7145 - val_loss: 0.5718 - val_accuracy: 0.7114\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5796 - accuracy: 0.7321 - val_loss: 0.5668 - val_accuracy: 0.7164\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5702 - accuracy: 0.6912 - val_loss: 0.5630 - val_accuracy: 0.7214\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5738 - accuracy: 0.7199 - val_loss: 0.5617 - val_accuracy: 0.7164\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5757 - accuracy: 0.6979 - val_loss: 0.5723 - val_accuracy: 0.7065\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5622 - accuracy: 0.7087 - val_loss: 0.5618 - val_accuracy: 0.7164\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7303 - val_loss: 0.5646 - val_accuracy: 0.7214\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5328 - accuracy: 0.7601 - val_loss: 0.5792 - val_accuracy: 0.7264\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5670 - accuracy: 0.7132 - val_loss: 0.5575 - val_accuracy: 0.7264\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5453 - accuracy: 0.7423 - val_loss: 0.5899 - val_accuracy: 0.7065\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.7342 - val_loss: 0.5705 - val_accuracy: 0.7114\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5972 - accuracy: 0.6934 - val_loss: 0.5627 - val_accuracy: 0.7264\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5691 - accuracy: 0.7130 - val_loss: 0.6228 - val_accuracy: 0.6816\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5965 - accuracy: 0.6788 - val_loss: 0.5777 - val_accuracy: 0.6965\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.7271 - val_loss: 0.5737 - val_accuracy: 0.7015\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.7086 - val_loss: 0.5527 - val_accuracy: 0.7214\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5650 - accuracy: 0.7327 - val_loss: 0.5495 - val_accuracy: 0.7214\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5549 - accuracy: 0.7350 - val_loss: 0.5713 - val_accuracy: 0.7214\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5667 - accuracy: 0.7002 - val_loss: 0.5501 - val_accuracy: 0.7413\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.7043 - val_loss: 0.5586 - val_accuracy: 0.7264\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5775 - accuracy: 0.7002 - val_loss: 0.5662 - val_accuracy: 0.7065\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5599 - accuracy: 0.7403 - val_loss: 0.5549 - val_accuracy: 0.7214\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7273 - val_loss: 0.5529 - val_accuracy: 0.7313\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.7189 - val_loss: 0.5526 - val_accuracy: 0.7413\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7149 - val_loss: 0.5548 - val_accuracy: 0.7313\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.7170 - val_loss: 0.5575 - val_accuracy: 0.7313\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7363 - val_loss: 0.6045 - val_accuracy: 0.6816\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.6936 - val_loss: 0.5481 - val_accuracy: 0.7413\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.7182 - val_loss: 0.5469 - val_accuracy: 0.7463\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.7155 - val_loss: 0.5781 - val_accuracy: 0.7114\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5584 - accuracy: 0.7351 - val_loss: 0.6095 - val_accuracy: 0.6617\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.6319 - val_loss: 0.5676 - val_accuracy: 0.7065\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5552 - accuracy: 0.7323 - val_loss: 0.5579 - val_accuracy: 0.7264\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5363 - accuracy: 0.7539 - val_loss: 0.5515 - val_accuracy: 0.7363\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5214 - accuracy: 0.7426 - val_loss: 0.5627 - val_accuracy: 0.7264\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5568 - accuracy: 0.7054 - val_loss: 0.5456 - val_accuracy: 0.7512\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5566 - accuracy: 0.7051 - val_loss: 0.5536 - val_accuracy: 0.7214\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5350 - accuracy: 0.7307 - val_loss: 0.5460 - val_accuracy: 0.7363\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.7130 - val_loss: 0.5419 - val_accuracy: 0.7512\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.7145 - val_loss: 0.5499 - val_accuracy: 0.7313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d68037080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ndMb-wpIwg",
        "outputId": "d9fbdf8e-36c7-455e-b28a-1ee7a46a3906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get model predictions for validation data\r\n",
        "y_pred3 = model3.predict(X_val1)\r\n",
        "print(y_pred3[:10])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.30680233]\n",
            " [0.502591  ]\n",
            " [0.40875232]\n",
            " [0.28097302]\n",
            " [0.52724844]\n",
            " [0.00419253]\n",
            " [0.4450607 ]\n",
            " [0.21976706]\n",
            " [0.6424153 ]\n",
            " [0.08760211]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkUKxmOSpRsR",
        "outputId": "8bde5a55-7350-4636-dae3-4e3589c2964e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_categorical3 = []\r\n",
        "for pred in y_pred3:\r\n",
        "  if pred > 0.5:\r\n",
        "    y_pred_categorical3.append(1)\r\n",
        "  else:\r\n",
        "    y_pred_categorical3.append(0)\r\n",
        "  \r\n",
        "\r\n",
        "print(y_pred_categorical3[:10])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALhdIZCnpbQH",
        "outputId": "2724af23-b695-459c-e931-17de70690d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# measure accuracy\r\n",
        "accuracy = metrics.accuracy_score(y_val1, y_pred_categorical3)\r\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7313432835820896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0leJ1koqyZe"
      },
      "source": [
        "**Test** **preformance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdnLCmtQq2ZZ",
        "outputId": "98b27a2e-a19f-4671-a36d-be0600f0e686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test predictions \r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df_test)}')\r\n",
        "\r\n",
        "X_test = df_test.drop(['Id'], axis=1)\r\n",
        "print(X_test.info())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 100\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      100 non-null    int64  \n",
            " 1   A2      100 non-null    int64  \n",
            " 2   A3      100 non-null    int64  \n",
            " 3   A4      100 non-null    int64  \n",
            " 4   A5      100 non-null    int64  \n",
            " 5   A6      100 non-null    float64\n",
            " 6   A7      100 non-null    float64\n",
            " 7   A8      100 non-null    int64  \n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 6.4 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdwA2SQ0rAvZ",
        "outputId": "e9124c8a-0ef5-47c3-bcf8-85abb0878cb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_pred = model3.predict(X_test) #Test predictions using model 3 \r\n",
        "print(test_pred)\r\n",
        "\r\n",
        "test_pred_categorical = [1 if pred > 0.5 else 0 for pred in test_pred]\r\n",
        "print(test_pred_categorical)\r\n",
        "\r\n",
        "final_predictions = test_pred\r\n",
        "\r\n",
        "df_submission = pd.DataFrame(df_test['Id'])\r\n",
        "df_submission['Class'] = final_predictions\r\n",
        "\r\n",
        "# save data frame to .csv file\r\n",
        "df_submission.to_csv('/content/test-predictions.csv', index=False)\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6906524 ]\n",
            " [0.31238183]\n",
            " [0.60296506]\n",
            " [0.37187183]\n",
            " [0.01306203]\n",
            " [0.46803492]\n",
            " [0.0869478 ]\n",
            " [0.5675461 ]\n",
            " [0.28984487]\n",
            " [0.34823263]\n",
            " [0.5196429 ]\n",
            " [0.43518776]\n",
            " [0.06853339]\n",
            " [0.54215217]\n",
            " [0.34538785]\n",
            " [0.33629525]\n",
            " [0.01573771]\n",
            " [0.4401108 ]\n",
            " [0.45422408]\n",
            " [0.41002953]\n",
            " [0.41519907]\n",
            " [0.52424   ]\n",
            " [0.18805614]\n",
            " [0.25316644]\n",
            " [0.2410121 ]\n",
            " [0.48656923]\n",
            " [0.23147893]\n",
            " [0.47148883]\n",
            " [0.38266888]\n",
            " [0.5085595 ]\n",
            " [0.36231074]\n",
            " [0.5041066 ]\n",
            " [0.43163323]\n",
            " [0.20389533]\n",
            " [0.37828946]\n",
            " [0.5539669 ]\n",
            " [0.13510749]\n",
            " [0.11081085]\n",
            " [0.23610139]\n",
            " [0.63543314]\n",
            " [0.46848089]\n",
            " [0.48458698]\n",
            " [0.5564433 ]\n",
            " [0.21412447]\n",
            " [0.48004296]\n",
            " [0.5135564 ]\n",
            " [0.1806657 ]\n",
            " [0.87241066]\n",
            " [0.5588118 ]\n",
            " [0.22877303]\n",
            " [0.5529633 ]\n",
            " [0.19389689]\n",
            " [0.03673637]\n",
            " [0.50957054]\n",
            " [0.40030187]\n",
            " [0.17186755]\n",
            " [0.04777482]\n",
            " [0.18959412]\n",
            " [0.38853663]\n",
            " [0.403206  ]\n",
            " [0.458217  ]\n",
            " [0.4194145 ]\n",
            " [0.10546258]\n",
            " [0.2473926 ]\n",
            " [0.33029604]\n",
            " [0.48065692]\n",
            " [0.13584304]\n",
            " [0.29131895]\n",
            " [0.08443084]\n",
            " [0.12442434]\n",
            " [0.4604286 ]\n",
            " [0.18813273]\n",
            " [0.542813  ]\n",
            " [0.47783247]\n",
            " [0.3712706 ]\n",
            " [0.24836352]\n",
            " [0.41904458]\n",
            " [0.30965385]\n",
            " [0.2876544 ]\n",
            " [0.06053835]\n",
            " [0.63456225]\n",
            " [0.36933947]\n",
            " [0.506393  ]\n",
            " [0.09321085]\n",
            " [0.36727798]\n",
            " [0.5080053 ]\n",
            " [0.43727237]\n",
            " [0.12686434]\n",
            " [0.23016956]\n",
            " [0.32425958]\n",
            " [0.25949302]\n",
            " [0.38839594]\n",
            " [0.20923251]\n",
            " [0.571412  ]\n",
            " [0.23937446]\n",
            " [0.7442397 ]\n",
            " [0.3868023 ]\n",
            " [0.22622633]\n",
            " [0.3983195 ]\n",
            " [0.13578728]]\n",
            "[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "endauhOFJ8Az"
      },
      "source": [
        "N is number of hidden neurons-\r\n",
        "\r\n",
        "N = 2/3 the size of the input layer, plus the size of the output layer.\r\n",
        "N < twice the size of the input layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75jHR9y_J7kc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}