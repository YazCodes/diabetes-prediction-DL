{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetesprediction.ipynb",
      "provenance": [],
      "mount_file_id": "1Sh5PN5XmPoPghSLGkHUyVouf5VHFQ4MD",
      "authorship_tag": "ABX9TyMrxRjsAAXTPTH3SCcIEwaq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YazCodes/diabetes-prediction-DL/blob/main/diabetesprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi6SFTPTjTBV"
      },
      "source": [
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder #need to convert labels - strings into boolean values etc \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "88TE1P0RkWYD",
        "outputId": "3341f633-d1bd-4d0a-9292-1624044bc630"
      },
      "source": [
        "\r\n",
        "#Load training data \r\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/hospitaltrain (1).csv\")\r\n",
        "\r\n",
        "#Load test data\r\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/hospitaltest (1).csv\")\r\n",
        "\r\n",
        "print(f'Number of entries: {len(df_train)}')\r\n",
        "df_train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  A1   A2  A3  A4   A5    A6     A7  A8  Class\n",
              "0   1   6  148  72  35    0  33.6  0.627  50      1\n",
              "1   2   1   85  66  29    0  26.6  0.351  31      0\n",
              "2   3   8  183  64   0    0  23.3  0.672  32      1\n",
              "3   4   1   89  66  23   94  28.1  0.167  21      0\n",
              "4   5   0  137  40  35  168  43.1  2.288  33      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8tEDhLCo34S",
        "outputId": "93c24e42-a1f0-4b05-a35a-fb7376d35ac2"
      },
      "source": [
        "#data set inforation\r\n",
        "\r\n",
        "df_train.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 668 entries, 0 to 667\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Id      668 non-null    int64  \n",
            " 1   A1      668 non-null    int64  \n",
            " 2   A2      668 non-null    int64  \n",
            " 3   A3      668 non-null    int64  \n",
            " 4   A4      668 non-null    int64  \n",
            " 5   A5      668 non-null    int64  \n",
            " 6   A6      668 non-null    float64\n",
            " 7   A7      668 non-null    float64\n",
            " 8   A8      668 non-null    int64  \n",
            " 9   Class   668 non-null    int64  \n",
            "dtypes: float64(2), int64(8)\n",
            "memory usage: 52.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "rPJZhJxDpJtv",
        "outputId": "84eec461-df86-4126-cc8c-ecfa51e1a922"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "      <td>668.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>334.500000</td>\n",
              "      <td>3.812874</td>\n",
              "      <td>120.405689</td>\n",
              "      <td>68.748503</td>\n",
              "      <td>20.567365</td>\n",
              "      <td>79.654192</td>\n",
              "      <td>31.860180</td>\n",
              "      <td>0.477329</td>\n",
              "      <td>33.091317</td>\n",
              "      <td>0.345808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>192.979273</td>\n",
              "      <td>3.365672</td>\n",
              "      <td>32.291473</td>\n",
              "      <td>19.526392</td>\n",
              "      <td>16.020600</td>\n",
              "      <td>115.827750</td>\n",
              "      <td>7.827111</td>\n",
              "      <td>0.341398</td>\n",
              "      <td>11.711386</td>\n",
              "      <td>0.475988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>167.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.100000</td>\n",
              "      <td>0.238750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>334.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>501.250000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>36.500000</td>\n",
              "      <td>0.641250</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>668.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Id          A1          A2  ...          A7          A8       Class\n",
              "count  668.000000  668.000000  668.000000  ...  668.000000  668.000000  668.000000\n",
              "mean   334.500000    3.812874  120.405689  ...    0.477329   33.091317    0.345808\n",
              "std    192.979273    3.365672   32.291473  ...    0.341398   11.711386    0.475988\n",
              "min      1.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
              "25%    167.750000    1.000000   99.000000  ...    0.238750   24.000000    0.000000\n",
              "50%    334.500000    3.000000  116.000000  ...    0.377000   29.000000    0.000000\n",
              "75%    501.250000    6.000000  140.000000  ...    0.641250   40.000000    1.000000\n",
              "max    668.000000   17.000000  199.000000  ...    2.420000   81.000000    1.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "UA3s_7kppTf9",
        "outputId": "f5c05006-0c35-4319-cc1e-507a7b7e24f5"
      },
      "source": [
        "# Summarise class details\r\n",
        "sns.countplot(x=df_train['Class'])\r\n",
        "#Class - 0 or 1 (1= tested positive for diabetes)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fead41d0f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "RmeV8gbdqaEx",
        "outputId": "1a7df083-5764-4bda-fe8e-3a3a18c25b08"
      },
      "source": [
        "#Data pre-processing \r\n",
        "df_train.isnull().values.any() #No missing values \r\n",
        "#The data has a lot of 0 values. But it is not appropriate to use data cleaning to replace the 0 values in the A5 column. \r\n",
        "#As the A5 column represents the amount of insulin a patient has it would be wrong of us to replace the 0 values with a mean value. \r\n",
        "#We don't want to alter patient records.\r\n",
        "\r\n",
        "#removing unnecessary columns\r\n",
        "#x is training data it contains features and models - 'Class' is something we need to PREDICT therefore we need to drop that column \r\n",
        "X = df_train.drop(['Id', 'Class'], axis=1) #Class is not a feature it's just a label  axis = 1 shows we are using columns \r\n",
        "print(X.info())\r\n",
        "X.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 668 entries, 0 to 667\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      668 non-null    int64  \n",
            " 1   A2      668 non-null    int64  \n",
            " 2   A3      668 non-null    int64  \n",
            " 3   A4      668 non-null    int64  \n",
            " 4   A5      668 non-null    int64  \n",
            " 5   A6      668 non-null    float64\n",
            " 6   A7      668 non-null    float64\n",
            " 7   A8      668 non-null    int64  \n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 41.9 KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A1   A2  A3  A4   A5    A6     A7  A8\n",
              "0   6  148  72  35    0  33.6  0.627  50\n",
              "1   1   85  66  29    0  26.6  0.351  31\n",
              "2   8  183  64   0    0  23.3  0.672  32\n",
              "3   1   89  66  23   94  28.1  0.167  21\n",
              "4   0  137  40  35  168  43.1  2.288  33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIL48450w2No",
        "outputId": "3faf4c0e-07c1-43b0-96ed-a2aa621faf77"
      },
      "source": [
        "#Extracting labels and features \r\n",
        "\r\n",
        "#Extracting labels \r\n",
        "y= df_train['Class']\r\n",
        "print(y.value_counts())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    437\n",
            "1    231\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351n593syTkQ"
      },
      "source": [
        "#Since the labels 0 and 1 are already are numerical values they do not need to be converted for the model.\r\n",
        "#If the labels were in a catergorical state then you could use the label encoder to convert them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9NK1cVpqy-zh",
        "outputId": "1ec76e1b-5b48-4ce9-85e8-eb447389833f"
      },
      "source": [
        "#MODEL ONE\r\n",
        "\r\n",
        "#Using 8 features and 2 hidden layers \r\n",
        "#building the model - using training data \r\n",
        "#calculating if the probability is closer to 0 or 1 \r\n",
        "X1 = X.iloc[:, 0:8] #locating part of the data frame the first 8 and call it X1 \r\n",
        "X1.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A1   A2  A3  A4   A5    A6     A7  A8\n",
              "0   6  148  72  35    0  33.6  0.627  50\n",
              "1   1   85  66  29    0  26.6  0.351  31\n",
              "2   8  183  64   0    0  23.3  0.672  32\n",
              "3   1   89  66  23   94  28.1  0.167  21\n",
              "4   0  137  40  35  168  43.1  2.288  33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgw1Q-xjzWxy",
        "outputId": "23a97915-ce9a-47cf-9a6a-562e41e11a84"
      },
      "source": [
        "#Spliting the data into train (70%) and validation (30%)\r\n",
        "X_train1, X_val1, y_train1, y_val1 = train_test_split(X1, y, test_size=0.3, random_state=100) #random state - regenerate the split again \r\n",
        "print(f'training data set size: {len(X_train1)}')\r\n",
        "print(f'validation data set size: {len(X_val1)}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data set size: 467\n",
            "validation data set size: 201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNzyZXHZz5oE",
        "outputId": "a1c4c102-60b1-4595-a755-d33127c109fa"
      },
      "source": [
        "#Building the model \r\n",
        "# define the keras model\r\n",
        "model1 = Sequential()\r\n",
        "model1.add(Dense(12, input_dim=8, activation='relu')) #Defining our hidden layer - adding the layers to the model, a dence layer, 12 neurons, we selected 8 features so 8 input dimentions .\r\n",
        "model1.add(Dense(8, activation='relu')) #second hidden layer\r\n",
        "#using relu for hidden layers not for output layers \r\n",
        "model1.add(Dense(1, activation='sigmoid')) #creating our output layer with one neurone \r\n",
        "\r\n",
        "model1.summary()\r\n",
        "\r\n",
        "#parameters = the total of weights and bias "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kK_3_1R2ATw"
      },
      "source": [
        "# compile the keras model\r\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCNWYhra2Knu",
        "outputId": "ab04d4f3-644f-4b19-ddbb-6ea1014954cd"
      },
      "source": [
        "# train model\r\n",
        "#model1.fit(X_train1, y_train1, batch_size=50, epochs=60, validation_data=(X_val1, y_val1)) #change depending on your dataset  batch_size and epochs- you have to look at the accuracy of the dataset \r\n",
        "\r\n",
        "#Epoch 60/60\r\n",
        "#10/10 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6782 - val_loss: 0.6478 - val_accuracy: 0.6716"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "10/10 [==============================] - 1s 31ms/step - loss: 3.7418 - accuracy: 0.3991 - val_loss: 2.4649 - val_accuracy: 0.4428\n",
            "Epoch 2/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4980 - accuracy: 0.4369 - val_loss: 2.0681 - val_accuracy: 0.4279\n",
            "Epoch 3/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.5355 - accuracy: 0.4316 - val_loss: 1.7451 - val_accuracy: 0.4478\n",
            "Epoch 4/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9790 - accuracy: 0.4600 - val_loss: 1.4849 - val_accuracy: 0.4428\n",
            "Epoch 5/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0643 - accuracy: 0.4625 - val_loss: 1.3298 - val_accuracy: 0.4478\n",
            "Epoch 6/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5816 - accuracy: 0.4646 - val_loss: 1.2303 - val_accuracy: 0.4577\n",
            "Epoch 7/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3786 - accuracy: 0.4792 - val_loss: 1.1309 - val_accuracy: 0.4726\n",
            "Epoch 8/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2712 - accuracy: 0.5071 - val_loss: 1.0922 - val_accuracy: 0.4627\n",
            "Epoch 9/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1167 - accuracy: 0.5538 - val_loss: 1.0410 - val_accuracy: 0.4776\n",
            "Epoch 10/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9809 - accuracy: 0.5627 - val_loss: 1.0755 - val_accuracy: 0.4776\n",
            "Epoch 11/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9061 - accuracy: 0.5681 - val_loss: 0.9736 - val_accuracy: 0.4876\n",
            "Epoch 12/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.5633 - val_loss: 1.0241 - val_accuracy: 0.4776\n",
            "Epoch 13/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8837 - accuracy: 0.5867 - val_loss: 0.9625 - val_accuracy: 0.5124\n",
            "Epoch 14/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8536 - accuracy: 0.5948 - val_loss: 0.9334 - val_accuracy: 0.5224\n",
            "Epoch 15/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.8415 - accuracy: 0.6238 - val_loss: 0.9075 - val_accuracy: 0.5423\n",
            "Epoch 16/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8322 - accuracy: 0.6030 - val_loss: 0.9195 - val_accuracy: 0.5124\n",
            "Epoch 17/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8098 - accuracy: 0.6036 - val_loss: 0.8738 - val_accuracy: 0.5622\n",
            "Epoch 18/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7719 - accuracy: 0.6172 - val_loss: 0.9072 - val_accuracy: 0.5274\n",
            "Epoch 19/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8093 - accuracy: 0.6016 - val_loss: 0.8539 - val_accuracy: 0.5672\n",
            "Epoch 20/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7939 - accuracy: 0.6326 - val_loss: 0.8631 - val_accuracy: 0.5572\n",
            "Epoch 21/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7544 - accuracy: 0.6225 - val_loss: 0.8344 - val_accuracy: 0.5672\n",
            "Epoch 22/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7227 - accuracy: 0.6447 - val_loss: 0.8374 - val_accuracy: 0.5721\n",
            "Epoch 23/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6620 - accuracy: 0.6783 - val_loss: 0.8155 - val_accuracy: 0.5821\n",
            "Epoch 24/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7533 - accuracy: 0.6303 - val_loss: 0.8184 - val_accuracy: 0.5721\n",
            "Epoch 25/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7058 - accuracy: 0.6505 - val_loss: 0.8112 - val_accuracy: 0.5771\n",
            "Epoch 26/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.6637 - val_loss: 0.7908 - val_accuracy: 0.5970\n",
            "Epoch 27/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7065 - accuracy: 0.6635 - val_loss: 0.7961 - val_accuracy: 0.5970\n",
            "Epoch 28/60\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.7029 - accuracy: 0.6521 - val_loss: 0.7871 - val_accuracy: 0.5920\n",
            "Epoch 29/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6706 - accuracy: 0.6636 - val_loss: 0.7743 - val_accuracy: 0.6169\n",
            "Epoch 30/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.6630 - val_loss: 0.7613 - val_accuracy: 0.6169\n",
            "Epoch 31/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6580 - accuracy: 0.6734 - val_loss: 0.7847 - val_accuracy: 0.5821\n",
            "Epoch 32/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6755 - val_loss: 0.7593 - val_accuracy: 0.6070\n",
            "Epoch 33/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6647 - accuracy: 0.6621 - val_loss: 0.7532 - val_accuracy: 0.6119\n",
            "Epoch 34/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.6660 - val_loss: 0.7419 - val_accuracy: 0.6219\n",
            "Epoch 35/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.6499 - val_loss: 0.7541 - val_accuracy: 0.6020\n",
            "Epoch 36/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6317 - accuracy: 0.7025 - val_loss: 0.7305 - val_accuracy: 0.6418\n",
            "Epoch 37/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6407 - accuracy: 0.6802 - val_loss: 0.7326 - val_accuracy: 0.6318\n",
            "Epoch 38/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6984 - val_loss: 0.7203 - val_accuracy: 0.6219\n",
            "Epoch 39/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.6591 - val_loss: 0.7303 - val_accuracy: 0.6169\n",
            "Epoch 40/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6622 - val_loss: 0.7130 - val_accuracy: 0.6517\n",
            "Epoch 41/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.7019 - val_loss: 0.7179 - val_accuracy: 0.6318\n",
            "Epoch 42/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6628 - accuracy: 0.6507 - val_loss: 0.7070 - val_accuracy: 0.6468\n",
            "Epoch 43/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.6840 - val_loss: 0.7047 - val_accuracy: 0.6318\n",
            "Epoch 44/60\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.7027 - val_loss: 0.7009 - val_accuracy: 0.6269\n",
            "Epoch 45/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6238 - accuracy: 0.6981 - val_loss: 0.6975 - val_accuracy: 0.6418\n",
            "Epoch 46/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6006 - accuracy: 0.7040 - val_loss: 0.6940 - val_accuracy: 0.6418\n",
            "Epoch 47/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6359 - accuracy: 0.6867 - val_loss: 0.6905 - val_accuracy: 0.6468\n",
            "Epoch 48/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.6785 - val_loss: 0.6824 - val_accuracy: 0.6517\n",
            "Epoch 49/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7042 - val_loss: 0.6804 - val_accuracy: 0.6418\n",
            "Epoch 50/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7105 - val_loss: 0.6687 - val_accuracy: 0.6567\n",
            "Epoch 51/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.6833 - val_loss: 0.6775 - val_accuracy: 0.6368\n",
            "Epoch 52/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6756 - val_loss: 0.6718 - val_accuracy: 0.6517\n",
            "Epoch 53/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7200 - val_loss: 0.6638 - val_accuracy: 0.6517\n",
            "Epoch 54/60\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5746 - accuracy: 0.7280 - val_loss: 0.6617 - val_accuracy: 0.6517\n",
            "Epoch 55/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.6846 - val_loss: 0.6737 - val_accuracy: 0.6318\n",
            "Epoch 56/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.6850 - val_loss: 0.6603 - val_accuracy: 0.6517\n",
            "Epoch 57/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.6834 - val_loss: 0.6679 - val_accuracy: 0.6517\n",
            "Epoch 58/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.6744 - val_loss: 0.6593 - val_accuracy: 0.6468\n",
            "Epoch 59/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.6903 - val_loss: 0.6664 - val_accuracy: 0.6318\n",
            "Epoch 60/60\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6782 - val_loss: 0.6478 - val_accuracy: 0.6716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea97153978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dTfiIz32ifC",
        "outputId": "f854ccd1-f11d-446f-fa78-5ba270c9902a"
      },
      "source": [
        "#Train model 2 \r\n",
        "#model1.fit(X_train1, y_train1, batch_size=40, epochs=50, validation_data=(X_val1, y_val1)) #change depending on your dataset  batch_size and epochs- you have to look at the accuracy of the dataset "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5927 - accuracy: 0.6809 - val_loss: 0.6664 - val_accuracy: 0.6418\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.6959 - val_loss: 0.6439 - val_accuracy: 0.6617\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.6895 - val_loss: 0.6651 - val_accuracy: 0.6368\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7024 - val_loss: 0.6347 - val_accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.6895 - val_loss: 0.6927 - val_accuracy: 0.6368\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6874 - val_loss: 0.6353 - val_accuracy: 0.6617\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6959 - val_loss: 0.6375 - val_accuracy: 0.6617\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.6916 - val_loss: 0.6286 - val_accuracy: 0.6716\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.6981 - val_loss: 0.6374 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.7045 - val_loss: 0.6416 - val_accuracy: 0.6617\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7109 - val_loss: 0.6285 - val_accuracy: 0.6716\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7088 - val_loss: 0.6426 - val_accuracy: 0.6468\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7173 - val_loss: 0.6198 - val_accuracy: 0.6766\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.6938 - val_loss: 0.6418 - val_accuracy: 0.6617\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7173 - val_loss: 0.6175 - val_accuracy: 0.6866\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.7002 - val_loss: 0.6222 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5687 - accuracy: 0.7002 - val_loss: 0.6424 - val_accuracy: 0.6617\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.6895 - val_loss: 0.6141 - val_accuracy: 0.6866\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7002 - val_loss: 0.6254 - val_accuracy: 0.6816\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7002 - val_loss: 0.6226 - val_accuracy: 0.6716\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7152 - val_loss: 0.6194 - val_accuracy: 0.6766\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7024 - val_loss: 0.6260 - val_accuracy: 0.6716\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7152 - val_loss: 0.6267 - val_accuracy: 0.6716\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7088 - val_loss: 0.6349 - val_accuracy: 0.6716\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7131 - val_loss: 0.6096 - val_accuracy: 0.6915\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7045 - val_loss: 0.6070 - val_accuracy: 0.6866\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.6959 - val_loss: 0.6356 - val_accuracy: 0.6766\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7024 - val_loss: 0.6102 - val_accuracy: 0.6866\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7002 - val_loss: 0.6023 - val_accuracy: 0.6965\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7173 - val_loss: 0.6136 - val_accuracy: 0.6766\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7173 - val_loss: 0.6090 - val_accuracy: 0.6766\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7024 - val_loss: 0.6229 - val_accuracy: 0.6766\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.7281 - val_loss: 0.6033 - val_accuracy: 0.6965\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7045 - val_loss: 0.6141 - val_accuracy: 0.6766\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7302 - val_loss: 0.6003 - val_accuracy: 0.6915\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7088 - val_loss: 0.6219 - val_accuracy: 0.6866\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5521 - accuracy: 0.7195 - val_loss: 0.6096 - val_accuracy: 0.6816\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7045 - val_loss: 0.6055 - val_accuracy: 0.6816\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7045 - val_loss: 0.6167 - val_accuracy: 0.6866\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7302 - val_loss: 0.5952 - val_accuracy: 0.7015\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7109 - val_loss: 0.6031 - val_accuracy: 0.6716\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7109 - val_loss: 0.6065 - val_accuracy: 0.6866\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7323 - val_loss: 0.5960 - val_accuracy: 0.6965\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7109 - val_loss: 0.6257 - val_accuracy: 0.6816\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7152 - val_loss: 0.5970 - val_accuracy: 0.7065\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7109 - val_loss: 0.5953 - val_accuracy: 0.6915\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7024 - val_loss: 0.6067 - val_accuracy: 0.6716\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.7195 - val_loss: 0.5919 - val_accuracy: 0.7065\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7281 - val_loss: 0.5919 - val_accuracy: 0.7114\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7066 - val_loss: 0.5973 - val_accuracy: 0.6816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea939b25f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNwyM4Kt3Gbo",
        "outputId": "bd9fad31-d188-4af1-c7f9-ebe662a4d132"
      },
      "source": [
        "# train model 3 - The better one \r\n",
        "model1.fit(X_train1, y_train1, batch_size=60, epochs=70, validation_data=(X_val1, y_val1)) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5391 - accuracy: 0.7173 - val_loss: 0.5970 - val_accuracy: 0.6965\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7152 - val_loss: 0.5974 - val_accuracy: 0.6915\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7173 - val_loss: 0.5990 - val_accuracy: 0.6766\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7109 - val_loss: 0.5890 - val_accuracy: 0.7015\n",
            "Epoch 5/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7345 - val_loss: 0.6005 - val_accuracy: 0.6716\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7259 - val_loss: 0.5915 - val_accuracy: 0.7015\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7152 - val_loss: 0.5974 - val_accuracy: 0.6766\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7345 - val_loss: 0.5933 - val_accuracy: 0.6915\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5339 - accuracy: 0.7152 - val_loss: 0.5909 - val_accuracy: 0.6965\n",
            "Epoch 10/70\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5340 - accuracy: 0.7195 - val_loss: 0.5962 - val_accuracy: 0.6766\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7281 - val_loss: 0.5888 - val_accuracy: 0.7015\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7216 - val_loss: 0.5937 - val_accuracy: 0.6866\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7259 - val_loss: 0.5930 - val_accuracy: 0.6866\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.7302 - val_loss: 0.5921 - val_accuracy: 0.6866\n",
            "Epoch 15/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7281 - val_loss: 0.5917 - val_accuracy: 0.6915\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.7238 - val_loss: 0.5852 - val_accuracy: 0.7114\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7409 - val_loss: 0.6003 - val_accuracy: 0.6816\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7430 - val_loss: 0.5859 - val_accuracy: 0.7065\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.7195 - val_loss: 0.5905 - val_accuracy: 0.6965\n",
            "Epoch 20/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7323 - val_loss: 0.5925 - val_accuracy: 0.6866\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7109 - val_loss: 0.5828 - val_accuracy: 0.7164\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 0.7409 - val_loss: 0.5960 - val_accuracy: 0.6816\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7281 - val_loss: 0.5868 - val_accuracy: 0.7015\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5324 - accuracy: 0.7216 - val_loss: 0.5861 - val_accuracy: 0.7114\n",
            "Epoch 25/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.7323 - val_loss: 0.5913 - val_accuracy: 0.6915\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.7281 - val_loss: 0.5832 - val_accuracy: 0.7065\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.7323 - val_loss: 0.5970 - val_accuracy: 0.6915\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7388 - val_loss: 0.5806 - val_accuracy: 0.7264\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7173 - val_loss: 0.5992 - val_accuracy: 0.6965\n",
            "Epoch 30/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7323 - val_loss: 0.5815 - val_accuracy: 0.7164\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7259 - val_loss: 0.5906 - val_accuracy: 0.6866\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.7238 - val_loss: 0.5777 - val_accuracy: 0.7164\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7302 - val_loss: 0.5901 - val_accuracy: 0.6766\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.7323 - val_loss: 0.5778 - val_accuracy: 0.7114\n",
            "Epoch 35/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7238 - val_loss: 0.5780 - val_accuracy: 0.7114\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7516 - val_loss: 0.5865 - val_accuracy: 0.6915\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7281 - val_loss: 0.5766 - val_accuracy: 0.7114\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7173 - val_loss: 0.5846 - val_accuracy: 0.6915\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.7537 - val_loss: 0.5876 - val_accuracy: 0.6816\n",
            "Epoch 40/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7302 - val_loss: 0.5758 - val_accuracy: 0.7164\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7281 - val_loss: 0.5758 - val_accuracy: 0.7015\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7473 - val_loss: 0.5800 - val_accuracy: 0.7015\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.7109 - val_loss: 0.5738 - val_accuracy: 0.7313\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7430 - val_loss: 0.5987 - val_accuracy: 0.6816\n",
            "Epoch 45/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7238 - val_loss: 0.5691 - val_accuracy: 0.7313\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5276 - accuracy: 0.7173 - val_loss: 0.5909 - val_accuracy: 0.6915\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5261 - accuracy: 0.7259 - val_loss: 0.5744 - val_accuracy: 0.7114\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5218 - accuracy: 0.7238 - val_loss: 0.5763 - val_accuracy: 0.7015\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.7366 - val_loss: 0.5753 - val_accuracy: 0.6965\n",
            "Epoch 50/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7366 - val_loss: 0.5726 - val_accuracy: 0.7114\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.7066 - val_loss: 0.5794 - val_accuracy: 0.6965\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.7281 - val_loss: 0.5729 - val_accuracy: 0.7015\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5198 - accuracy: 0.7452 - val_loss: 0.5682 - val_accuracy: 0.7264\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.7323 - val_loss: 0.5833 - val_accuracy: 0.6915\n",
            "Epoch 55/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.7366 - val_loss: 0.5674 - val_accuracy: 0.7363\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5205 - accuracy: 0.7281 - val_loss: 0.5762 - val_accuracy: 0.7015\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7430 - val_loss: 0.5745 - val_accuracy: 0.7164\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.7281 - val_loss: 0.5727 - val_accuracy: 0.7015\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7259 - val_loss: 0.5679 - val_accuracy: 0.7313\n",
            "Epoch 60/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7323 - val_loss: 0.5747 - val_accuracy: 0.7164\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.7388 - val_loss: 0.5631 - val_accuracy: 0.7264\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.7281 - val_loss: 0.5760 - val_accuracy: 0.6965\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.7409 - val_loss: 0.5670 - val_accuracy: 0.7164\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7281 - val_loss: 0.5701 - val_accuracy: 0.7164\n",
            "Epoch 65/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7323 - val_loss: 0.5696 - val_accuracy: 0.7114\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5174 - accuracy: 0.7452 - val_loss: 0.5743 - val_accuracy: 0.7015\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.7388 - val_loss: 0.5636 - val_accuracy: 0.7363\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.7430 - val_loss: 0.5730 - val_accuracy: 0.6965\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7259 - val_loss: 0.5641 - val_accuracy: 0.7313\n",
            "Epoch 70/70\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.7430 - val_loss: 0.5730 - val_accuracy: 0.7065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fea94a662e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf002nDM5UkZ",
        "outputId": "e6c38758-7179-4b6a-d301-98965282861a"
      },
      "source": [
        "# get model predictions for validation data\r\n",
        "y_pred1 = model1.predict(X_val1)\r\n",
        "print(y_pred1[:10])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.39571267]\n",
            " [0.6151204 ]\n",
            " [0.25974202]\n",
            " [0.29754144]\n",
            " [0.6689728 ]\n",
            " [0.07901052]\n",
            " [0.45796472]\n",
            " [0.25729826]\n",
            " [0.49921706]\n",
            " [0.19692037]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEnPKMmz5fo-",
        "outputId": "3eb7f53d-f946-4c84-9001-1fc6fdd0dfc1"
      },
      "source": [
        "y_pred_categorical1 = []\r\n",
        "for pred in y_pred1:\r\n",
        "  if pred > 0.5:\r\n",
        "    y_pred_categorical1.append(1)\r\n",
        "  else:\r\n",
        "    y_pred_categorical1.append(0)\r\n",
        "  \r\n",
        "\r\n",
        "print(y_pred_categorical1[:10])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuJwdXGW5kzU",
        "outputId": "5991b315-55d0-450d-9d06-11256ebdd911"
      },
      "source": [
        "# measure accuracy\r\n",
        "accuracy = metrics.accuracy_score(y_val1, y_pred_categorical1)\r\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7064676616915423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z78eYca152_i",
        "outputId": "b63cb923-34b5-486c-b577-9eb941447bec"
      },
      "source": [
        "# Test predictions \r\n",
        "# summarise the details\r\n",
        "print(f'Number of entries: {len(df_test)}')\r\n",
        "\r\n",
        "X_test = df_test.drop(['Id'], axis=1)\r\n",
        "print(X_test.info())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of entries: 100\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      100 non-null    int64  \n",
            " 1   A2      100 non-null    int64  \n",
            " 2   A3      100 non-null    int64  \n",
            " 3   A4      100 non-null    int64  \n",
            " 4   A5      100 non-null    int64  \n",
            " 5   A6      100 non-null    float64\n",
            " 6   A7      100 non-null    float64\n",
            " 7   A8      100 non-null    int64  \n",
            "dtypes: float64(2), int64(6)\n",
            "memory usage: 6.4 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21GFKDPF61QT",
        "outputId": "f361df28-7510-4a78-a89f-1d030792ec3e"
      },
      "source": [
        "test_pred = model1.predict(X_test)\r\n",
        "print(test_pred)\r\n",
        "\r\n",
        "test_pred_categorical = [1 if pred > 0.5 else 0 for pred in test_pred]\r\n",
        "print(test_pred_categorical)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6.1670500e-01]\n",
            " [4.0108013e-01]\n",
            " [5.5382913e-01]\n",
            " [3.6843187e-01]\n",
            " [7.4215233e-02]\n",
            " [3.1066418e-01]\n",
            " [3.8011372e-02]\n",
            " [8.7752426e-01]\n",
            " [3.6958769e-01]\n",
            " [3.3615547e-01]\n",
            " [5.8491218e-01]\n",
            " [5.1153076e-01]\n",
            " [1.9247583e-01]\n",
            " [6.8173057e-01]\n",
            " [2.2306883e-01]\n",
            " [4.2488885e-01]\n",
            " [2.1788073e-01]\n",
            " [5.6389308e-01]\n",
            " [4.4475320e-01]\n",
            " [4.2440104e-01]\n",
            " [5.8358949e-01]\n",
            " [4.3531960e-01]\n",
            " [2.7281338e-01]\n",
            " [4.1215789e-01]\n",
            " [2.3370531e-01]\n",
            " [5.0952250e-01]\n",
            " [2.9193351e-01]\n",
            " [6.9836164e-01]\n",
            " [3.7749407e-01]\n",
            " [6.7842388e-01]\n",
            " [2.5988436e-01]\n",
            " [5.0237584e-01]\n",
            " [5.0591540e-01]\n",
            " [2.6176292e-01]\n",
            " [4.9230459e-01]\n",
            " [7.2806209e-02]\n",
            " [2.5834864e-01]\n",
            " [1.5262809e-01]\n",
            " [2.2357702e-04]\n",
            " [4.6244460e-01]\n",
            " [3.7376133e-01]\n",
            " [3.8505986e-01]\n",
            " [6.7009068e-01]\n",
            " [5.8048785e-02]\n",
            " [5.1456678e-01]\n",
            " [5.6728077e-01]\n",
            " [2.6953053e-01]\n",
            " [7.1896064e-01]\n",
            " [6.4362508e-01]\n",
            " [2.0246115e-01]\n",
            " [6.0327101e-01]\n",
            " [1.8403277e-01]\n",
            " [6.9309115e-02]\n",
            " [5.7909638e-01]\n",
            " [4.0243250e-01]\n",
            " [2.0683786e-01]\n",
            " [1.6896915e-01]\n",
            " [4.2605686e-01]\n",
            " [4.2179465e-01]\n",
            " [4.6230161e-01]\n",
            " [5.6287014e-01]\n",
            " [3.4256312e-01]\n",
            " [2.2026658e-01]\n",
            " [3.8032386e-01]\n",
            " [2.8575176e-01]\n",
            " [5.4433501e-01]\n",
            " [1.8875256e-01]\n",
            " [4.5557112e-01]\n",
            " [2.9351765e-01]\n",
            " [9.2710763e-02]\n",
            " [3.4757781e-01]\n",
            " [2.4648431e-01]\n",
            " [4.3660468e-01]\n",
            " [3.1674916e-01]\n",
            " [3.1918627e-01]\n",
            " [3.7716168e-01]\n",
            " [4.8513234e-01]\n",
            " [3.7203610e-01]\n",
            " [4.2345315e-01]\n",
            " [9.6200436e-02]\n",
            " [6.0031468e-01]\n",
            " [5.2567148e-01]\n",
            " [4.7512159e-01]\n",
            " [1.9095862e-01]\n",
            " [3.5676733e-01]\n",
            " [6.7962736e-01]\n",
            " [5.0844365e-01]\n",
            " [2.4032232e-01]\n",
            " [2.9885677e-01]\n",
            " [3.3573624e-01]\n",
            " [3.2338911e-01]\n",
            " [2.4974224e-01]\n",
            " [8.4557861e-02]\n",
            " [7.0458645e-01]\n",
            " [2.6381627e-01]\n",
            " [6.5710878e-01]\n",
            " [4.1373497e-01]\n",
            " [3.6964214e-01]\n",
            " [2.4133831e-01]\n",
            " [2.1269867e-01]]\n",
            "[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}